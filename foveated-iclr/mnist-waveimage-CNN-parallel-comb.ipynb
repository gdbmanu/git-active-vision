{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : generaliser à images 32x32, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from waveimage import WaveImage, calc_dim, calc_U, mnist_reshape_32\n",
    "from waveimage import WaveImage, calc_dim, calc_U, mnist_reshape_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def calc_U(shape, h, h_max): #dim_i, dim_j):\n",
    "    dim_i, dim_j = calc_dim(shape, h, h_max)\n",
    "    U = []\n",
    "    for i in range(dim_i):\n",
    "        for j in range(dim_j):\n",
    "            U += [(i, j)]\n",
    "    return U'''\n",
    "from waveimage import calc_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_reshape_32_buf(x):\n",
    "    assert x.shape == (28 * 28,)\n",
    "    image = x.reshape(28,28)\n",
    "    image = np.append(np.zeros((2,28)), image, axis = 0)\n",
    "    image = np.append(image, np.zeros((2,28)), axis = 0)\n",
    "    image = np.append(np.zeros((32,2)), image, axis = 1)\n",
    "    image = np.append(image, np.zeros((32,2)), axis = 1)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creation de la base d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"mnist-waveimage-train-mu-Sigma-rho.pkl\"):\n",
    "    \n",
    "    B_train = []\n",
    "    for i in range(len(mnist.train.images)):\n",
    "        if i % 1000 == 0 :\n",
    "            sys.stdout.write('\\rstep %d' % i) \n",
    "            sys.stdout.flush()\n",
    "        c = mnist.train.labels[i]\n",
    "        image = mnist_reshape_32(mnist.train.images[i])\n",
    "        w = WaveImage(image = image)\n",
    "        data = w.get_data()\n",
    "        for h in range(w.get_h_max()):\n",
    "            data_h = w.get_data()[h]\n",
    "            for u in data_h:\n",
    "                v = data_h[u]\n",
    "                B_train += [(v,(c,h,u))]   \n",
    "                \n",
    "    ### Dictionnaire (Base d'apprentissage)    \n",
    "    \n",
    "    Data_train = [[],[],[],[],[],[],[],[],[],[]]\n",
    "    for c in range(10):\n",
    "        Data_train[c] = [{},{},{},{},{},{}] \n",
    "\n",
    "    for d in B_train:\n",
    "        v = d[0]\n",
    "        c = d[1][0]\n",
    "        h = d[1][1]\n",
    "        u = d[1][2]\n",
    "        if u in Data_train[c][h]:\n",
    "            Data_train[c][h][u] += [v]\n",
    "        else:\n",
    "            Data_train[c][h][u] = [v]\n",
    "            \n",
    "    ### Probas elementaires         \n",
    "    mu = []\n",
    "    Sigma = []\n",
    "    rho = []\n",
    "    for c in range(10):\n",
    "        mu += [{}]\n",
    "        Sigma += [{}]\n",
    "        rho += [{}]\n",
    "        for h in range(0,6):\n",
    "            mu[c][h] = {}\n",
    "            Sigma[c][h] = {}\n",
    "            rho[c][h] = {}\n",
    "            for u in calc_U((32, 32), h, 6):\n",
    "                if u in Data_train[c][h]:\n",
    "                    data = []\n",
    "                    cpt = 0\n",
    "                    for v in Data_train[c][h][u]:\n",
    "                        if np.linalg.norm(v) < 1e-16:\n",
    "                            cpt += 1\n",
    "                        else:\n",
    "                            data += [v]\n",
    "                    #if h == -1 :\n",
    "                    #    print len(data)\n",
    "                    if len(data) > 1:\n",
    "                        mu[c][h][u] = np.mean(data, 0) #Data[c][h][u],0)\n",
    "                        Sigma[c][h][u] = np.cov(np.array(data).T) #Data[c][h][u]).T)\n",
    "                        rho[c][h][u] = float(cpt) / len(Data_train[c][h][u])\n",
    "                    else:\n",
    "                        mu[c][h][u] = np.zeros(3)\n",
    "                        Sigma[c][h][u] = np.zeros((3,3))\n",
    "                        rho[c][h][u] = 1.\n",
    "    del B_train, Data_train \n",
    "    pickle.dump((mu, Sigma, rho),  open(\"mnist-waveimage-train-mu-Sigma-rho.pkl\", \"wb\"))\n",
    "else:\n",
    "    mu, Sigma, rho = pickle.load(open(\"mnist-waveimage-train-mu-Sigma-rho.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nb_pos = 1 + 1 * 1 + 2 * 2 + 4 * 4 + 8 * 8 + 16 * 16\n",
    "print \"# weak classifiers (# pos):\", nb_pos\n",
    "print \"# total examples :\", len(B_train)\n",
    "print \"# total examples / weak classifier :\", len(B_train) / nb_pos\n",
    "\n",
    "# weak classifiers (# pos): 342\n",
    "# total examples : 18810000\n",
    "# total examples / weak classifier : 55000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9000"
     ]
    }
   ],
   "source": [
    "B_test = []\n",
    "for i in range(len(mnist.test.images)):\n",
    "    if i % 1000 == 0 :\n",
    "        sys.stdout.write('\\rstep %d' % i) \n",
    "        sys.stdout.flush()\n",
    "    c = mnist.test.labels[i]\n",
    "    image = mnist_reshape_32(mnist.test.images[i])\n",
    "    w = WaveImage(image = image)\n",
    "    data = w.get_data()\n",
    "    for h in range(w.get_h_max()):\n",
    "        data_h = w.get_data()[h]\n",
    "        for u in data_h:\n",
    "            v = data_h[u]\n",
    "            B_test += [(v,(c,h,u))]                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionnaire (Base de test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test = [[],[],[],[],[],[],[],[],[],[]]\n",
    "for c in range(10):\n",
    "    Data_test[c] = [{},{},{},{},{},{}] \n",
    "    \n",
    "for d in B_test:\n",
    "    v = d[0]\n",
    "    c = d[1][0]\n",
    "    h = d[1][1]\n",
    "    u = d[1][2]\n",
    "    if u in Data_test[c][h]:\n",
    "        Data_test[c][h][u] += [v]\n",
    "    else:\n",
    "        Data_test[c][h][u] = [v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Construction du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_tensor_data(batch_x):\n",
    "    batch_size, _ = batch_x.shape\n",
    "    wave_tensor = {}\n",
    "    for h in range(6):\n",
    "        if h == 0:\n",
    "            h_size = 1\n",
    "            wave_tensor[h] = np.zeros((batch_size, h_size, h_size, 1))\n",
    "        else:\n",
    "            h_size = 2**(h - 1)\n",
    "            wave_tensor[h] = np.zeros((batch_size, h_size, h_size, 3))\n",
    "    for num_batch in range(batch_size):\n",
    "        image = mnist_reshape_32(batch_x[num_batch])\n",
    "        w = WaveImage(image = image)\n",
    "        for h in range(w.get_h_max()):\n",
    "            data_h = w.get_data()[h]\n",
    "            if h == 0:\n",
    "                wave_tensor[h][num_batch][0][0][0] = data_h[(0,0)]\n",
    "            else:\n",
    "                for u in data_h:\n",
    "                    wave_tensor[h][num_batch][u[0]][u[1]][:] = data_h[u]\n",
    "    return wave_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_test_tensor(BATCH_SIZE = 1):\n",
    "    test_tensor = {}\n",
    "    test_tensor[5] = np.zeros((BATCH_SIZE, DIM_5, DIM_5, DEPTH_WAV))\n",
    "    test_tensor[4] = np.zeros((BATCH_SIZE, DIM_4, DIM_4, DEPTH_WAV))\n",
    "    test_tensor[3] = np.zeros((BATCH_SIZE, DIM_3, DIM_3, DEPTH_WAV))\n",
    "    test_tensor[2] = np.zeros((BATCH_SIZE, DIM_2, DIM_2, DEPTH_WAV))\n",
    "    test_tensor[1] = np.zeros((BATCH_SIZE, DIM_1, DIM_1, DEPTH_WAV))\n",
    "    test_tensor[0] = np.zeros((BATCH_SIZE, 1, 1, 1))\n",
    "    return test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_test_tensor(v, h, u, test_tensor, BATCH_SIZE = 1):\n",
    "    test_tensor[h][0][u[0]][u[1]][:] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_test_tensor(test_tensor):\n",
    "    test_tensor_copy = {}\n",
    "    test_tensor_copy[5] = np.copy(test_tensor[5])\n",
    "    test_tensor_copy[4] = np.copy(test_tensor[4])\n",
    "    test_tensor_copy[3] = np.copy(test_tensor[3])\n",
    "    test_tensor_copy[2] = np.copy(test_tensor[2])\n",
    "    test_tensor_copy[1] = np.copy(test_tensor[1])\n",
    "    test_tensor_copy[0] = np.copy(test_tensor[0])\n",
    "    return test_tensor_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Obj:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Obj()\n",
    "params.batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = mnist.train.next_batch(params.batch_size)\n",
    "wave_tensor = wave_tensor_data(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction \n",
    "+ 5 couches convolutionnelles : 16 x 16 --> 8 x 8 ; 8 x 8 --> 4 x 4 etc\n",
    "+ 1 couche FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_WAV = 3\n",
    "\n",
    "DIM_5 = 16\n",
    "WIDTH = 2\n",
    "\n",
    "DEPTH_4 = 32\n",
    "DIM_4 = DIM_5 / WIDTH # 8\n",
    "\n",
    "DEPTH_3 = 64\n",
    "DIM_3 = DIM_4 / WIDTH # 4\n",
    "\n",
    "DEPTH_2 = 128\n",
    "DIM_2 = DIM_3 / WIDTH # 2\n",
    "\n",
    "DEPTH_1 = 256\n",
    "DIM_1 = DIM_2 / WIDTH # 1\n",
    "\n",
    "DIM_HIDDEN = 500\n",
    "\n",
    "NB_LABEL = 10\n",
    "\n",
    "STD = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 8192, 32768, 131072, 130000, 5000)\n"
     ]
    }
   ],
   "source": [
    "nb_param_54 = (DEPTH_WAV * WIDTH * WIDTH) * DEPTH_4\n",
    "nb_param_43 = (DEPTH_4 * WIDTH * WIDTH) * DEPTH_3\n",
    "nb_param_32 = (DEPTH_3 * WIDTH * WIDTH) * DEPTH_2\n",
    "nb_param_21 = (DEPTH_2 * WIDTH * WIDTH) * DEPTH_1\n",
    "nb_param_1h = (DEPTH_1 + DEPTH_WAV + 1) * DIM_HIDDEN\n",
    "nb_param_hr = DIM_HIDDEN * NB_LABEL\n",
    "print (nb_param_54, nb_param_43, nb_param_32, nb_param_21, nb_param_1h, nb_param_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEPTH_1 + DEPTH_2 + DEPTH_3 + DEPTH_4 + DEPTH_WAV + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, stddev = 0.1, name = \"dummy\", reuse = False):\n",
    "    #initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    #initial = tf.zeros(shape)\n",
    "    if reuse:\n",
    "        return tf.get_variable(name)\n",
    "    else:\n",
    "        initial = tf.random_normal(shape, stddev = stddev)\n",
    "        return tf.Variable(initial, name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_5 = tf.placeholder(tf.float32, shape=[None, DIM_5, DIM_5, DEPTH_WAV])\n",
    "x_4 = tf.placeholder(tf.float32, shape=[None, DIM_4, DIM_4, DEPTH_WAV])\n",
    "x_3 = tf.placeholder(tf.float32, shape=[None, DIM_3, DIM_3, DEPTH_WAV])\n",
    "x_2 = tf.placeholder(tf.float32, shape=[None, DIM_2, DIM_2, DEPTH_WAV])\n",
    "x_1 = tf.placeholder(tf.float32, shape=[None, DIM_1, DIM_1, DEPTH_WAV])\n",
    "x_0 = tf.placeholder(tf.float32, shape=[None, 1, 1, 1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "batch_phase = tf.placeholder(tf.bool, name='bn_phase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 --> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "W_conv_54_flux1 = weight_variable([WIDTH, WIDTH, DEPTH_WAV, DEPTH_4], \\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_WAV), \\\n",
    "                            name = \"W_conv_54_flux1\")\n",
    "# Graph construction\n",
    "h_conv_4_flux1 = tf.nn.conv2d(x_5, W_conv_54_flux1, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_4_flux1') \n",
    "#h_conv_4_flux1 = tf.nn.conv2d(x_5, W_conv_54_flux1, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_4_flux1') \n",
    "#h_pool_4_flux1 = tf.nn.max_pool(h_conv_4_flux1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_4_flux1')\n",
    "#h_pool_4_bn_flux1 = tf.contrib.layers.batch_norm(h_pool_4_flux1, center=True, scale=True, is_training=batch_phase, scope='h_pool_4_flux1', updates_collections=None)\n",
    "z_conv_4_flux1 = tf.nn.relu(h_conv_4_flux1)\n",
    "\n",
    "#h_conv_4 = tf.nn.conv2d(x_5, W_conv_54, strides=[1, WIDTH, WIDTH, 1], padding='VALID', name='h_conv_4') \n",
    "#h_conv_4_bn = tf.contrib.layers.batch_norm(h_conv_4, center=True, scale=True, is_training=batch_phase, scope='h_conv_4', updates_collections=None)\n",
    "#z_conv_4 = tf.nn.relu(h_conv_4_bn)\n",
    "\n",
    "#cat_conv_4 = tf.concat((z_conv_4, x_4), axis = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 --> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "W_conv_43_flux1 = weight_variable([WIDTH, WIDTH, DEPTH_4, DEPTH_3],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_4), \\\n",
    "                            name = \"W_conv_43_flux1\")\n",
    "\n",
    "h_conv_3_flux1 = tf.nn.conv2d(z_conv_4_flux1, W_conv_43_flux1, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_3_flux1') \n",
    "#h_conv_3_flux1 = tf.nn.conv2d(z_conv_4_flux1, W_conv_43_flux1, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_3_flux1') \n",
    "#h_pool_3_flux1 = tf.nn.max_pool(h_conv_3_flux1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_3_flux1')\n",
    "#h_pool_3_bn_flux1 = tf.contrib.layers.batch_norm(h_pool_3_flux1, center=True, scale=True, is_training=batch_phase, scope='h_pool_3_flux1', updates_collections=None)\n",
    "z_conv_3_flux1 = tf.nn.relu(h_conv_3_flux1)\n",
    "\n",
    "# Graph construction\n",
    "#h_conv_3 = tf.nn.conv2d(cat_conv_4, W_conv_43, strides=[1, WIDTH, WIDTH, 1], padding='VALID', name='h_conv_3') \n",
    "#h_conv_3_bn = tf.contrib.layers.batch_norm(h_conv_3, center=True, scale=True, is_training=batch_phase, scope='h_conv_3', updates_collections=None)\n",
    "#z_conv_3 = tf.nn.relu(h_conv_3_bn)\n",
    "\n",
    "#cat_conv_3 = tf.concat((z_conv_3, x_3), axis = 3)\n",
    "\n",
    "W_conv_43_flux2 = weight_variable([WIDTH, WIDTH, DEPTH_WAV, DEPTH_4],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_WAV), \\\n",
    "                            name = \"W_conv_43_flux1\")\n",
    "\n",
    "h_conv_3_flux2 = tf.nn.conv2d(x_4, W_conv_43_flux2, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_3_flux2') \n",
    "#h_conv_3_flux2 = tf.nn.conv2d(x_4, W_conv_43_flux2, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_3_flux2') \n",
    "#h_pool_3_flux2 = tf.nn.max_pool(h_conv_3_flux2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_3_flux2')\n",
    "#h_pool_3_bn_flux2 = tf.contrib.layers.batch_norm(h_pool_3_flux2, center=True, scale=True, is_training=batch_phase, scope='h_pool_3_flux2', updates_collections=None)\n",
    "z_conv_3_flux2 = tf.nn.relu(h_conv_3_flux2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 --> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "W_conv_32_flux1 = weight_variable([WIDTH, WIDTH, DEPTH_3 , DEPTH_2],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_3 ), \\\n",
    "                            name = \"W_conv_32_flux1\")\n",
    "\n",
    "# Graph construction\n",
    "h_conv_2_flux1 = tf.nn.conv2d(z_conv_3_flux1, W_conv_32_flux1, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_2_flux1') \n",
    "#h_conv_2_flux1 = tf.nn.conv2d(z_conv_3_flux1, W_conv_32_flux1, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_2_flux1') \n",
    "#h_pool_2_flux1 = tf.nn.max_pool(h_conv_2_flux1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_2_flux1')\n",
    "#h_pool_2_bn_flux1 = tf.contrib.layers.batch_norm(h_pool_2_flux1, center=True, scale=True, is_training=batch_phase, scope='h_pool_2_flux1', updates_collections=None)\n",
    "z_conv_2_flux1 = tf.nn.relu(h_conv_2_flux1)\n",
    "\n",
    "#h_conv_2 = tf.nn.conv2d(cat_conv_3, W_conv_32, strides=[1, WIDTH, WIDTH, 1], padding='VALID', name='h_conv_2') \n",
    "#h_conv_2_bn = tf.contrib.layers.batch_norm(h_conv_2, center=True, scale=True, is_training=batch_phase, scope='h_conv_2', updates_collections=None)\n",
    "#z_conv_2 = tf.nn.relu(h_conv_2_bn)\n",
    "\n",
    "#cat_conv_2 = tf.concat((z_conv_2, x_2), axis = 3)\n",
    "\n",
    "W_conv_32_flux2 = weight_variable([WIDTH, WIDTH, DEPTH_4 , DEPTH_3],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_4 ), \\\n",
    "                            name = \"W_conv_32_flux1\")\n",
    "\n",
    "# Graph construction\n",
    "h_conv_2_flux2 = tf.nn.conv2d(z_conv_3_flux2, W_conv_32_flux2, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_2_flux2') \n",
    "#h_conv_2_flux2 = tf.nn.conv2d(z_conv_3_flux2, W_conv_32_flux2, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_2_flux2') \n",
    "#h_pool_2_flux2 = tf.nn.max_pool(h_conv_2_flux2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_2_flux2')\n",
    "#h_pool_2_bn_flux2 = tf.contrib.layers.batch_norm(h_pool_2_flux2, center=True, scale=True, is_training=batch_phase, scope='h_pool_2_flux2', updates_collections=None)\n",
    "z_conv_2_flux2 = tf.nn.relu(h_conv_2_flux2)\n",
    "\n",
    "W_conv_32_flux3 = weight_variable([WIDTH, WIDTH, DEPTH_WAV , DEPTH_4],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_WAV ), \\\n",
    "                            name = \"W_conv_32_flux3\")\n",
    "\n",
    "# Graph construction\n",
    "h_conv_2_flux3 = tf.nn.conv2d(x_3, W_conv_32_flux3, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_2_flux3') \n",
    "#h_conv_2_flux3 = tf.nn.conv2d(x_3, W_conv_32_flux3, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_2_flux3') \n",
    "#h_pool_2_flux3 = tf.nn.max_pool(h_conv_2_flux3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_2_flux3')\n",
    "#h_pool_2_bn_flux3 = tf.contrib.layers.batch_norm(h_pool_2_flux3, center=True, scale=True, is_training=batch_phase, scope='h_pool_2_flux3', updates_collections=None)\n",
    "z_conv_2_flux3 = tf.nn.relu(h_conv_2_flux3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 --> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "W_conv_21_flux1 = weight_variable([WIDTH, WIDTH, DEPTH_2, DEPTH_1],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_2), \\\n",
    "                            name = \"W_conv_21_flux1\")\n",
    "\n",
    "h_conv_1_flux1 = tf.nn.conv2d(z_conv_2_flux1, W_conv_21_flux1, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_1_flux1') \n",
    "#h_conv_1_flux1 = tf.nn.conv2d(z_conv_2_flux1, W_conv_21_flux1, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_1_flux1') \n",
    "#h_pool_1_flux1 = tf.nn.max_pool(h_conv_1_flux1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_1_flux1')\n",
    "#h_pool_1_bn_flux1 = tf.contrib.layers.batch_norm(h_pool_1_flux1, center=True, scale=True, is_training=batch_phase, scope='h_pool_1_flux1', updates_collections=None)\n",
    "z_conv_1_flux1 = tf.nn.relu(h_conv_1_flux1)\n",
    "\n",
    "# Graph construction\n",
    "#h_conv_1 = tf.nn.conv2d(cat_conv_2, W_conv_21, strides=[1, WIDTH, WIDTH, 1], padding='VALID', name='h_conv_1') \n",
    "#h_conv_1_bn = tf.contrib.layers.batch_norm(h_conv_1, center=True, scale=True, is_training=batch_phase, scope='h_conv_1', updates_collections=None)\n",
    "#z_conv_1 = tf.nn.relu(h_conv_1_bn)\n",
    "\n",
    "W_conv_21_flux2 = weight_variable([WIDTH, WIDTH, DEPTH_3, DEPTH_2],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_3), \\\n",
    "                            name = \"W_conv_21_flux2\")\n",
    "\n",
    "h_conv_1_flux2 = tf.nn.conv2d(z_conv_2_flux2, W_conv_21_flux2, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_1_flux2') \n",
    "#h_conv_1_flux2 = tf.nn.conv2d(z_conv_2_flux2, W_conv_21_flux2, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_1_flux2') \n",
    "#h_pool_1_flux2 = tf.nn.max_pool(h_conv_1_flux2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_1_flux2')\n",
    "#h_pool_1_bn_flux2 = tf.contrib.layers.batch_norm(h_pool_1_flux2, center=True, scale=True, is_training=batch_phase, scope='h_pool_1_flux2', updates_collections=None)\n",
    "z_conv_1_flux2 = tf.nn.relu(h_conv_1_flux2)\n",
    "\n",
    "##\n",
    "\n",
    "W_conv_21_flux3 = weight_variable([WIDTH, WIDTH, DEPTH_4, DEPTH_3],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_4), \\\n",
    "                            name = \"W_conv_21_flux3\")\n",
    "\n",
    "h_conv_1_flux3 = tf.nn.conv2d(z_conv_2_flux3, W_conv_21_flux3, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_1_flux2') \n",
    "#h_conv_1_flux3 = tf.nn.conv2d(z_conv_2_flux3, W_conv_21_flux3, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_1_flux2') \n",
    "#h_pool_1_flux3 = tf.nn.max_pool(h_conv_1_flux3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_1_flux3')\n",
    "#h_pool_1_bn_flux3 = tf.contrib.layers.batch_norm(h_pool_1_flux3, center=True, scale=True, is_training=batch_phase, scope='h_pool_1_flux3', updates_collections=None)\n",
    "z_conv_1_flux3 = tf.nn.relu(h_conv_1_flux3)\n",
    "\n",
    "##\n",
    "\n",
    "W_conv_21_flux4 = weight_variable([WIDTH, WIDTH, DEPTH_WAV, DEPTH_4],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_WAV), \\\n",
    "                            name = \"W_conv_21_flux4\")\n",
    "\n",
    "h_conv_1_flux4 = tf.nn.conv2d(x_2, W_conv_21_flux4, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_1_flux4') \n",
    "#h_conv_1_flux4 = tf.nn.conv2d(x_2, W_conv_21_flux4, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_1_flux4') \n",
    "#h_pool_1_flux4 = tf.nn.max_pool(h_conv_1_flux4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_1_flux4')\n",
    "#h_pool_1_bn_flux4 = tf.contrib.layers.batch_norm(h_pool_1_flux4, center=True, scale=True, is_training=batch_phase, scope='h_pool_1_flux4', updates_collections=None)\n",
    "z_conv_1_flux4 = tf.nn.relu(h_conv_1_flux4)\n",
    "\n",
    "##\n",
    "\n",
    "#cat_conv_1 = tf.concat((z_conv_1_flux1, z_conv_1_flux2, z_conv_1_flux3, z_conv_1_flux4, x_1, x_0), axis = 3)\n",
    "#z_flat1 = tf.reshape(cat_conv_1, [-1, DEPTH_1 + DEPTH_2 + DEPTH_3 + DEPTH_4 + DEPTH_WAV + 1])#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_conv_1_flux5 = tf.concat((x_1, x_0), axis = 3)\n",
    "W_hidden_flux5 = weight_variable([DEPTH_WAV + 1, DIM_HIDDEN], stddev = STD / (DEPTH_WAV + 1), name = \"W_hidden_flux5\")\n",
    "h_hidden_flux5 = tf.matmul(tf.reshape(z_conv_1_flux5, [-1, DEPTH_WAV + 1]), W_hidden_flux5)\n",
    "z_hidden_flux5 = tf.nn.relu(h_hidden_flux5)\n",
    "\n",
    "z_concat_4 = tf.concat((tf.reshape(z_conv_1_flux4, [-1, DEPTH_4]), z_hidden_flux5), axis = 1)\n",
    "W_hidden_flux4 = weight_variable([DEPTH_4 + DIM_HIDDEN, DIM_HIDDEN], stddev = STD / (DEPTH_4 + DIM_HIDDEN), name = \"W_hidden_flux2\")\n",
    "h_hidden_flux4 = tf.matmul(z_concat_4, W_hidden_flux4)\n",
    "z_hidden_flux4 = tf.nn.relu(h_hidden_flux4)\n",
    "\n",
    "z_concat_3 = tf.concat((tf.reshape(z_conv_1_flux3, [-1, DEPTH_3]), z_hidden_flux4), axis = 1)\n",
    "W_hidden_flux3 = weight_variable([DEPTH_3 + DIM_HIDDEN, DIM_HIDDEN], stddev = STD / (DEPTH_3 + DIM_HIDDEN), name = \"W_hidden_flux3\")\n",
    "h_hidden_flux3 = tf.matmul(z_concat_3, W_hidden_flux3)\n",
    "z_hidden_flux3 = tf.nn.relu(h_hidden_flux3)\n",
    "\n",
    "z_concat_2 = tf.concat((tf.reshape(z_conv_1_flux2, [-1, DEPTH_2]), z_hidden_flux3), axis = 1)\n",
    "W_hidden_flux2 = weight_variable([DEPTH_2 + DIM_HIDDEN, DIM_HIDDEN], stddev = STD / (DEPTH_2 + DIM_HIDDEN), name = \"W_hidden_flux2\")\n",
    "h_hidden_flux2 = tf.matmul(z_concat_2, W_hidden_flux2)\n",
    "z_hidden_flux2 = tf.nn.relu(h_hidden_flux2)\n",
    "\n",
    "z_concat_1 = tf.concat((tf.reshape(z_conv_1_flux1, [-1, DEPTH_1]), z_hidden_flux2), axis = 1)\n",
    "W_hidden_flux1 = weight_variable([DEPTH_1 + DIM_HIDDEN, DIM_HIDDEN], stddev = STD / (DEPTH_1 + DIM_HIDDEN), name = \"W_hidden_flux1\")\n",
    "h_hidden_flux1 = tf.matmul(z_concat_1, W_hidden_flux1)\n",
    "z_hidden_flux1 = tf.nn.relu(h_hidden_flux1)\n",
    "\n",
    "#z_hidden_concat = tf.concat((z_hidden_flux1, z_hidden_flux2, z_hidden_flux3, z_hidden_flux4, z_hidden_flux5), axis = 1)\n",
    "W_hidden = weight_variable([DIM_HIDDEN, DIM_HIDDEN], stddev = STD / DIM_HIDDEN, name = \"W_hidden\")\n",
    "h_hidden = tf.matmul(z_hidden_flux1, W_hidden)\n",
    "z_hidden = tf.nn.relu(h_hidden)\n",
    "z_hidden_drop = tf.nn.dropout(z_hidden, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W_hidden = weight_variable([DEPTH_1 + DEPTH_2 + DEPTH_3 + DEPTH_4 + DEPTH_WAV + 1, DIM_HIDDEN], stddev = STD / (DEPTH_1 + DEPTH_2 + DEPTH_3 + DEPTH_4 + DEPTH_WAV + 1), name = \"W_hidden\")\n",
    "#h_hidden = tf.matmul(z_flat1, W_hidden)\n",
    "#z_hidden = tf.nn.relu(h_hidden)\n",
    "#z_hidden_drop = tf.nn.dropout(z_hidden, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### readout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_readout = weight_variable([DIM_HIDDEN, NB_LABEL], stddev = STD / DIM_HIDDEN, name = \"W_readout\")\n",
    "y_hat_logit = tf.matmul(z_hidden_drop, W_readout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss graph¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_hat_logit))\n",
    "\n",
    "#l1_regularizer = tf.contrib.layers.l1_regularizer(\n",
    "#   scale=0.005, scope=None\n",
    "#)\n",
    "#weights = tf.trainable_variables() # all vars of your graph\n",
    "#regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, weights)\n",
    "\n",
    "regularized_loss = classif_loss #+ regularization_penalty # this loss needs to be min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train graph¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer(1e-3).minimize(regularized_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_hat_logit, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = Obj()\n",
    "mem.num_epoch = []\n",
    "mem.classif_eval = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.n_epochs = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/mnist-waveimage-CNN-parallel-comb-500.ckpt\n"
     ]
    }
   ],
   "source": [
    "file_name = \"models/mnist-waveimage-CNN-parallel-comb-500\"\n",
    "\n",
    "if not os.path.isfile(file_name + \".ckpt.index\"):\n",
    "    for num_epoch in range (params.n_epochs):\n",
    "        if num_epoch % 10 == 0:\n",
    "            mem.num_epoch += [num_epoch]\n",
    "            x_test, y_test = mnist.test.next_batch(params.batch_size)\n",
    "            wave_tensor = wave_tensor_data(x_test)\n",
    "            classif_eval = accuracy.eval(feed_dict={x_5: wave_tensor[5],\\\n",
    "                                                    x_4: wave_tensor[4],\\\n",
    "                                                    x_3: wave_tensor[3],\\\n",
    "                                                    x_2: wave_tensor[2],\\\n",
    "                                                    x_1: wave_tensor[1],\\\n",
    "                                                    x_0: wave_tensor[0],\\\n",
    "                                                    y: y_test,\\\n",
    "                                                    keep_prob: 1,\\\n",
    "                                                    batch_phase:False})\n",
    "            mem.classif_eval += [classif_eval]\n",
    "            sys.stdout.write('\\rstep %d\\t classif : %.5f' \\\n",
    "                             % (num_epoch, \\\n",
    "                                classif_eval))\n",
    "        if num_epoch % 1000 == 0:\n",
    "            saver.save(sess,          file_name + \".ckpt\")\n",
    "            pickle.dump(mem,     open(file_name + \"_mem.pkl\", \"wb\"))\n",
    "        batch_x, batch_y = mnist.train.next_batch(params.batch_size) \n",
    "        wave_tensor = wave_tensor_data(batch_x)\n",
    "        train.run(feed_dict={x_5: wave_tensor[5],\\\n",
    "                              x_4: wave_tensor[4],\\\n",
    "                              x_3: wave_tensor[3],\\\n",
    "                              x_2: wave_tensor[2],\\\n",
    "                              x_1: wave_tensor[1],\\\n",
    "                              x_0: wave_tensor[0],\\\n",
    "                              y: batch_y,\\\n",
    "                              keep_prob: 0.9,\\\n",
    "                              batch_phase:True})\n",
    "else:\n",
    "    saver.restore(sess, file_name + \".ckpt\")\n",
    "    mem = pickle.load(open(file_name + \"_mem.pkl\", \"rb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f49f49bd190>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49e5e148d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mem.classif_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tests single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "test_tensor = {}\n",
    "test_tensor[5] = np.zeros((1, DIM_5, DIM_5, DEPTH_WAV))\n",
    "test_tensor[4] = np.zeros((1, DIM_4, DIM_4, DEPTH_WAV))\n",
    "test_tensor[3] = np.zeros((1, DIM_3, DIM_3, DEPTH_WAV))\n",
    "test_tensor[2] = np.zeros((1, DIM_2, DIM_2, DEPTH_WAV))\n",
    "test_tensor[1] = np.zeros((1, DIM_1, DIM_1, DEPTH_WAV))\n",
    "test_tensor[0] = np.zeros((1, 1, 1, 1))\n",
    "\n",
    "test = y_hat_logit.eval(feed_dict={ x_5: test_tensor[5],\\\n",
    "                                    x_4: test_tensor[4],\\\n",
    "                                    x_3: test_tensor[3],\\\n",
    "                                    x_2: test_tensor[2],\\\n",
    "                                    x_1: test_tensor[1],\\\n",
    "                                    x_0: test_tensor[0],\\\n",
    "                                    keep_prob: 1,\\\n",
    "                                    batch_phase:False})\n",
    "\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "classif : 0.98050"
     ]
    }
   ],
   "source": [
    "x_test, y_test = mnist.test.images, mnist.test.labels\n",
    "wave_tensor = wave_tensor_data(x_test)\n",
    "classif_eval = accuracy.eval(feed_dict={x_5: wave_tensor[5],\\\n",
    "                                        x_4: wave_tensor[4],\\\n",
    "                                        x_3: wave_tensor[3],\\\n",
    "                                        x_2: wave_tensor[2],\\\n",
    "                                        x_1: wave_tensor[1],\\\n",
    "                                        x_0: wave_tensor[0],\\\n",
    "                                        y: y_test,\\\n",
    "                                        keep_prob: 1,\\\n",
    "                                        batch_phase:False})\n",
    "sys.stdout.write('\\rclassif : %.5f' \\\n",
    "                 % (classif_eval,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-122284.15625  907066.25    -539082.6875   443167.03125 -784730.875\n",
      "   848306.6875  -424114.1875  -653379.3125   410418.71875  475477.53125]]\n",
      "[ 0. -1.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8FdKKT/0/0+9nwjzqO0oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49f46b8bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = 1\n",
    "ind_test = 2\n",
    "u_test = (7, 7)\n",
    "h_test = 5\n",
    "v = Data_test[c][h_test][u_test][ind_test]\n",
    "\n",
    "test_tensor = init_test_tensor()\n",
    "y_test = np.zeros((1, 10))\n",
    "y_test[0, c] = 1\n",
    "\n",
    "fill_test_tensor(v, h_test, u_test, test_tensor)\n",
    "test = y_hat_logit.eval(feed_dict={x_5: test_tensor[5],\\\n",
    "                                        x_4: test_tensor[4],\\\n",
    "                                        x_3: test_tensor[3],\\\n",
    "                                        x_2: test_tensor[2],\\\n",
    "                                        x_1: test_tensor[1],\\\n",
    "                                        x_0: test_tensor[0],\\\n",
    "                                        keep_prob: 1})\n",
    "print test\n",
    "plt.plot(test_tensor[h_test][0][u_test[0]][u_test[1]][:])\n",
    "print v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste des coordonnées par niveau : U[h], h $\\in$ 0..5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niveau  0  : \n",
      " U[ 0 ] : {(0, 0): 1}\n",
      "\n",
      "Niveau  1  : \n",
      " U[ 1 ] : {(0, 0): 1}\n",
      "\n",
      "Niveau  2  : \n",
      " U[ 2 ] : {(0, 1): 1, (1, 0): 1, (0, 0): 1, (1, 1): 1}\n",
      "\n",
      "Niveau  3  : \n",
      " U[ 3 ] : {(0, 1): 1, (1, 2): 1, (3, 2): 1, (0, 0): 1, (3, 3): 1, (3, 0): 1, (3, 1): 1, (2, 1): 1, (0, 2): 1, (2, 0): 1, (1, 3): 1, (2, 3): 1, (2, 2): 1, (1, 0): 1, (0, 3): 1, (1, 1): 1}\n",
      "\n",
      "Niveau  4  : \n",
      " U[ 4 ] : {(7, 3): 1, (4, 7): 1, (1, 3): 1, (6, 4): 1, (3, 0): 1, (5, 4): 1, (0, 7): 1, (5, 6): 1, (2, 6): 1, (1, 6): 1, (5, 1): 1, (3, 7): 1, (2, 5): 1, (0, 3): 1, (7, 2): 1, (4, 0): 1, (1, 2): 1, (6, 7): 1, (3, 3): 1, (2, 0): 1, (7, 6): 1, (4, 4): 1, (6, 3): 1, (1, 5): 1, (3, 6): 1, (2, 2): 1, (7, 7): 1, (5, 7): 1, (5, 3): 1, (4, 1): 1, (1, 1): 1, (2, 7): 1, (3, 2): 1, (0, 0): 1, (6, 6): 1, (5, 0): 1, (7, 1): 1, (4, 5): 1, (0, 4): 1, (5, 5): 1, (1, 4): 1, (6, 0): 1, (7, 5): 1, (2, 3): 1, (2, 1): 1, (4, 2): 1, (1, 0): 1, (6, 5): 1, (3, 5): 1, (0, 1): 1, (7, 0): 1, (4, 6): 1, (5, 2): 1, (6, 1): 1, (3, 1): 1, (0, 2): 1, (7, 4): 1, (0, 6): 1, (6, 2): 1, (4, 3): 1, (1, 7): 1, (0, 5): 1, (3, 4): 1, (2, 4): 1}\n",
      "\n",
      "Niveau  5  : \n",
      " U[ 5 ] : {(7, 3): 1, (6, 9): 1, (12, 1): 1, (11, 11): 1, (7, 12): 1, (14, 4): 1, (13, 4): 1, (12, 12): 1, (0, 7): 1, (15, 1): 1, (1, 6): 1, (0, 10): 1, (3, 7): 1, (2, 5): 1, (1, 11): 1, (8, 5): 1, (5, 8): 1, (4, 0): 1, (10, 8): 1, (9, 0): 1, (6, 7): 1, (5, 5): 1, (11, 5): 1, (10, 7): 1, (7, 6): 1, (6, 10): 1, (12, 6): 1, (15, 11): 1, (14, 1): 1, (13, 7): 1, (0, 4): 1, (15, 4): 1, (1, 1): 1, (8, 15): 1, (4, 10): 1, (3, 2): 1, (2, 6): 1, (9, 14): 1, (8, 2): 1, (5, 11): 1, (4, 5): 1, (10, 13): 1, (9, 3): 1, (6, 0): 1, (11, 0): 1, (7, 5): 1, (14, 15): 1, (12, 11): 1, (15, 14): 1, (14, 2): 1, (13, 10): 1, (0, 1): 1, (3, 12): 1, (1, 12): 1, (8, 12): 1, (4, 15): 1, (3, 1): 1, (2, 11): 1, (9, 9): 1, (5, 14): 1, (10, 14): 1, (6, 13): 1, (11, 15): 1, (7, 8): 1, (14, 8): 1, (13, 0): 1, (12, 8): 1, (15, 13): 1, (13, 13): 1, (0, 14): 1, (3, 11): 1, (2, 1): 1, (1, 15): 1, (8, 9): 1, (4, 12): 1, (2, 12): 1, (9, 4): 1, (5, 1): 1, (10, 3): 1, (7, 2): 1, (6, 14): 1, (12, 2): 1, (11, 10): 1, (7, 15): 1, (14, 5): 1, (13, 3): 1, (12, 13): 1, (15, 0): 1, (1, 5): 1, (0, 11): 1, (3, 6): 1, (2, 2): 1, (1, 10): 1, (8, 6): 1, (4, 1): 1, (10, 9): 1, (9, 7): 1, (6, 4): 1, (5, 4): 1, (11, 4): 1, (10, 4): 1, (7, 1): 1, (6, 11): 1, (12, 7): 1, (11, 9): 1, (15, 10): 1, (14, 6): 1, (13, 6): 1, (0, 5): 1, (15, 7): 1, (1, 0): 1, (0, 8): 1, (4, 11): 1, (3, 5): 1, (2, 7): 1, (9, 13): 1, (8, 3): 1, (5, 10): 1, (4, 6): 1, (10, 10): 1, (9, 2): 1, (6, 1): 1, (5, 7): 1, (11, 3): 1, (7, 4): 1, (14, 12): 1, (12, 4): 1, (15, 9): 1, (14, 3): 1, (13, 9): 1, (0, 2): 1, (3, 15): 1, (1, 3): 1, (8, 13): 1, (4, 8): 1, (3, 0): 1, (2, 8): 1, (9, 8): 1, (8, 0): 1, (5, 13): 1, (10, 15): 1, (6, 2): 1, (11, 14): 1, (7, 11): 1, (14, 9): 1, (12, 9): 1, (15, 12): 1, (13, 12): 1, (0, 15): 1, (3, 10): 1, (1, 14): 1, (8, 10): 1, (4, 13): 1, (2, 13): 1, (9, 11): 1, (5, 0): 1, (10, 0): 1, (6, 15): 1, (12, 3): 1, (11, 13): 1, (7, 14): 1, (14, 10): 1, (13, 2): 1, (12, 14): 1, (15, 3): 1, (13, 15): 1, (1, 4): 1, (0, 12): 1, (3, 9): 1, (2, 3): 1, (1, 9): 1, (8, 7): 1, (4, 2): 1, (2, 14): 1, (9, 6): 1, (6, 5): 1, (5, 3): 1, (11, 7): 1, (10, 5): 1, (7, 0): 1, (6, 8): 1, (12, 0): 1, (11, 8): 1, (7, 13): 1, (14, 7): 1, (13, 5): 1, (0, 6): 1, (15, 6): 1, (1, 7): 1, (0, 9): 1, (3, 4): 1, (2, 4): 1, (9, 12): 1, (8, 4): 1, (5, 9): 1, (4, 7): 1, (10, 11): 1, (9, 1): 1, (6, 6): 1, (5, 6): 1, (11, 2): 1, (10, 6): 1, (7, 7): 1, (14, 13): 1, (12, 5): 1, (15, 8): 1, (14, 0): 1, (13, 8): 1, (0, 3): 1, (15, 5): 1, (3, 14): 1, (1, 2): 1, (8, 14): 1, (4, 9): 1, (3, 3): 1, (2, 9): 1, (9, 15): 1, (8, 1): 1, (5, 12): 1, (4, 4): 1, (10, 12): 1, (6, 3): 1, (11, 1): 1, (7, 10): 1, (14, 14): 1, (12, 10): 1, (15, 15): 1, (13, 11): 1, (0, 0): 1, (3, 13): 1, (1, 13): 1, (8, 11): 1, (4, 14): 1, (2, 10): 1, (9, 10): 1, (5, 15): 1, (10, 1): 1, (6, 12): 1, (11, 12): 1, (7, 9): 1, (14, 11): 1, (13, 1): 1, (12, 15): 1, (15, 2): 1, (13, 14): 1, (0, 13): 1, (3, 8): 1, (2, 0): 1, (1, 8): 1, (8, 8): 1, (4, 3): 1, (2, 15): 1, (9, 5): 1, (5, 2): 1, (11, 6): 1, (10, 2): 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "axes = []\n",
    "h_max = 6\n",
    "shape = (32,32)\n",
    "\n",
    "U = {}\n",
    "for h in range(h_max):\n",
    "    #U_ref = {}\n",
    "    #for pos_i in axes[h]:\n",
    "    #    for pos_j in axes[h]:\n",
    "    #        U_ref[h] += [(pos_i, pos_j)]\n",
    "    U [h] = {}\n",
    "    dim_i, dim_j = calc_dim(shape, h, h_max)\n",
    "    for i in range(dim_i):\n",
    "        for j in range(dim_j):\n",
    "            U[h][(i,j)] = 1    \n",
    "    print 'Niveau ', h, ' : '\n",
    "    print ' U[' , h, '] :', U[h]\n",
    "    #print ' U_ref[h] :', U_ref[h]\n",
    "    print ''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction d'un arbre de coordonnées multi-niveau (descendants pour (i,j) au niveau h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fils_rec(shape, h, h_max, i, j):\n",
    "    \n",
    "    if h < h_max :\n",
    "        dim_i, dim_j = calc_dim(shape, h, h_max)\n",
    "        if i < dim_i and j < dim_j :\n",
    "            rep = [(h,(i,j)), [], [], [], []]\n",
    "            rep[1] = fils_rec(shape, h + 1, h_max, i * 2, j * 2)\n",
    "            rep[2] = fils_rec(shape, h + 1, h_max, i * 2, j * 2 + 1)\n",
    "            rep[3] = fils_rec(shape, h + 1, h_max, i * 2 + 1, j * 2)\n",
    "            rep[4] = fils_rec(shape, h + 1, h_max, i * 2 + 1, j * 2 + 1)\n",
    "        else:\n",
    "            rep = []\n",
    "    else:\n",
    "        rep = []\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (0, 0)), [(1, (0, 0)), [(2, (0, 0)), [(3, (0, 0)), [(4, (0, 0)), [(5, (0, 0)), [], [], [], []], [(5, (0, 1)), [], [], [], []], [(5, (1, 0)), [], [], [], []], [(5, (1, 1)), [], [], [], []]], [(4, (0, 1)), [(5, (0, 2)), [], [], [], []], [(5, (0, 3)), [], [], [], []], [(5, (1, 2)), [], [], [], []], [(5, (1, 3)), [], [], [], []]], [(4, (1, 0)), [(5, (2, 0)), [], [], [], []], [(5, (2, 1)), [], [], [], []], [(5, (3, 0)), [], [], [], []], [(5, (3, 1)), [], [], [], []]], [(4, (1, 1)), [(5, (2, 2)), [], [], [], []], [(5, (2, 3)), [], [], [], []], [(5, (3, 2)), [], [], [], []], [(5, (3, 3)), [], [], [], []]]], [(3, (0, 1)), [(4, (0, 2)), [(5, (0, 4)), [], [], [], []], [(5, (0, 5)), [], [], [], []], [(5, (1, 4)), [], [], [], []], [(5, (1, 5)), [], [], [], []]], [(4, (0, 3)), [(5, (0, 6)), [], [], [], []], [(5, (0, 7)), [], [], [], []], [(5, (1, 6)), [], [], [], []], [(5, (1, 7)), [], [], [], []]], [(4, (1, 2)), [(5, (2, 4)), [], [], [], []], [(5, (2, 5)), [], [], [], []], [(5, (3, 4)), [], [], [], []], [(5, (3, 5)), [], [], [], []]], [(4, (1, 3)), [(5, (2, 6)), [], [], [], []], [(5, (2, 7)), [], [], [], []], [(5, (3, 6)), [], [], [], []], [(5, (3, 7)), [], [], [], []]]], [(3, (1, 0)), [(4, (2, 0)), [(5, (4, 0)), [], [], [], []], [(5, (4, 1)), [], [], [], []], [(5, (5, 0)), [], [], [], []], [(5, (5, 1)), [], [], [], []]], [(4, (2, 1)), [(5, (4, 2)), [], [], [], []], [(5, (4, 3)), [], [], [], []], [(5, (5, 2)), [], [], [], []], [(5, (5, 3)), [], [], [], []]], [(4, (3, 0)), [(5, (6, 0)), [], [], [], []], [(5, (6, 1)), [], [], [], []], [(5, (7, 0)), [], [], [], []], [(5, (7, 1)), [], [], [], []]], [(4, (3, 1)), [(5, (6, 2)), [], [], [], []], [(5, (6, 3)), [], [], [], []], [(5, (7, 2)), [], [], [], []], [(5, (7, 3)), [], [], [], []]]], [(3, (1, 1)), [(4, (2, 2)), [(5, (4, 4)), [], [], [], []], [(5, (4, 5)), [], [], [], []], [(5, (5, 4)), [], [], [], []], [(5, (5, 5)), [], [], [], []]], [(4, (2, 3)), [(5, (4, 6)), [], [], [], []], [(5, (4, 7)), [], [], [], []], [(5, (5, 6)), [], [], [], []], [(5, (5, 7)), [], [], [], []]], [(4, (3, 2)), [(5, (6, 4)), [], [], [], []], [(5, (6, 5)), [], [], [], []], [(5, (7, 4)), [], [], [], []], [(5, (7, 5)), [], [], [], []]], [(4, (3, 3)), [(5, (6, 6)), [], [], [], []], [(5, (6, 7)), [], [], [], []], [(5, (7, 6)), [], [], [], []], [(5, (7, 7)), [], [], [], []]]]], [(2, (0, 1)), [(3, (0, 2)), [(4, (0, 4)), [(5, (0, 8)), [], [], [], []], [(5, (0, 9)), [], [], [], []], [(5, (1, 8)), [], [], [], []], [(5, (1, 9)), [], [], [], []]], [(4, (0, 5)), [(5, (0, 10)), [], [], [], []], [(5, (0, 11)), [], [], [], []], [(5, (1, 10)), [], [], [], []], [(5, (1, 11)), [], [], [], []]], [(4, (1, 4)), [(5, (2, 8)), [], [], [], []], [(5, (2, 9)), [], [], [], []], [(5, (3, 8)), [], [], [], []], [(5, (3, 9)), [], [], [], []]], [(4, (1, 5)), [(5, (2, 10)), [], [], [], []], [(5, (2, 11)), [], [], [], []], [(5, (3, 10)), [], [], [], []], [(5, (3, 11)), [], [], [], []]]], [(3, (0, 3)), [(4, (0, 6)), [(5, (0, 12)), [], [], [], []], [(5, (0, 13)), [], [], [], []], [(5, (1, 12)), [], [], [], []], [(5, (1, 13)), [], [], [], []]], [(4, (0, 7)), [(5, (0, 14)), [], [], [], []], [(5, (0, 15)), [], [], [], []], [(5, (1, 14)), [], [], [], []], [(5, (1, 15)), [], [], [], []]], [(4, (1, 6)), [(5, (2, 12)), [], [], [], []], [(5, (2, 13)), [], [], [], []], [(5, (3, 12)), [], [], [], []], [(5, (3, 13)), [], [], [], []]], [(4, (1, 7)), [(5, (2, 14)), [], [], [], []], [(5, (2, 15)), [], [], [], []], [(5, (3, 14)), [], [], [], []], [(5, (3, 15)), [], [], [], []]]], [(3, (1, 2)), [(4, (2, 4)), [(5, (4, 8)), [], [], [], []], [(5, (4, 9)), [], [], [], []], [(5, (5, 8)), [], [], [], []], [(5, (5, 9)), [], [], [], []]], [(4, (2, 5)), [(5, (4, 10)), [], [], [], []], [(5, (4, 11)), [], [], [], []], [(5, (5, 10)), [], [], [], []], [(5, (5, 11)), [], [], [], []]], [(4, (3, 4)), [(5, (6, 8)), [], [], [], []], [(5, (6, 9)), [], [], [], []], [(5, (7, 8)), [], [], [], []], [(5, (7, 9)), [], [], [], []]], [(4, (3, 5)), [(5, (6, 10)), [], [], [], []], [(5, (6, 11)), [], [], [], []], [(5, (7, 10)), [], [], [], []], [(5, (7, 11)), [], [], [], []]]], [(3, (1, 3)), [(4, (2, 6)), [(5, (4, 12)), [], [], [], []], [(5, (4, 13)), [], [], [], []], [(5, (5, 12)), [], [], [], []], [(5, (5, 13)), [], [], [], []]], [(4, (2, 7)), [(5, (4, 14)), [], [], [], []], [(5, (4, 15)), [], [], [], []], [(5, (5, 14)), [], [], [], []], [(5, (5, 15)), [], [], [], []]], [(4, (3, 6)), [(5, (6, 12)), [], [], [], []], [(5, (6, 13)), [], [], [], []], [(5, (7, 12)), [], [], [], []], [(5, (7, 13)), [], [], [], []]], [(4, (3, 7)), [(5, (6, 14)), [], [], [], []], [(5, (6, 15)), [], [], [], []], [(5, (7, 14)), [], [], [], []], [(5, (7, 15)), [], [], [], []]]]], [(2, (1, 0)), [(3, (2, 0)), [(4, (4, 0)), [(5, (8, 0)), [], [], [], []], [(5, (8, 1)), [], [], [], []], [(5, (9, 0)), [], [], [], []], [(5, (9, 1)), [], [], [], []]], [(4, (4, 1)), [(5, (8, 2)), [], [], [], []], [(5, (8, 3)), [], [], [], []], [(5, (9, 2)), [], [], [], []], [(5, (9, 3)), [], [], [], []]], [(4, (5, 0)), [(5, (10, 0)), [], [], [], []], [(5, (10, 1)), [], [], [], []], [(5, (11, 0)), [], [], [], []], [(5, (11, 1)), [], [], [], []]], [(4, (5, 1)), [(5, (10, 2)), [], [], [], []], [(5, (10, 3)), [], [], [], []], [(5, (11, 2)), [], [], [], []], [(5, (11, 3)), [], [], [], []]]], [(3, (2, 1)), [(4, (4, 2)), [(5, (8, 4)), [], [], [], []], [(5, (8, 5)), [], [], [], []], [(5, (9, 4)), [], [], [], []], [(5, (9, 5)), [], [], [], []]], [(4, (4, 3)), [(5, (8, 6)), [], [], [], []], [(5, (8, 7)), [], [], [], []], [(5, (9, 6)), [], [], [], []], [(5, (9, 7)), [], [], [], []]], [(4, (5, 2)), [(5, (10, 4)), [], [], [], []], [(5, (10, 5)), [], [], [], []], [(5, (11, 4)), [], [], [], []], [(5, (11, 5)), [], [], [], []]], [(4, (5, 3)), [(5, (10, 6)), [], [], [], []], [(5, (10, 7)), [], [], [], []], [(5, (11, 6)), [], [], [], []], [(5, (11, 7)), [], [], [], []]]], [(3, (3, 0)), [(4, (6, 0)), [(5, (12, 0)), [], [], [], []], [(5, (12, 1)), [], [], [], []], [(5, (13, 0)), [], [], [], []], [(5, (13, 1)), [], [], [], []]], [(4, (6, 1)), [(5, (12, 2)), [], [], [], []], [(5, (12, 3)), [], [], [], []], [(5, (13, 2)), [], [], [], []], [(5, (13, 3)), [], [], [], []]], [(4, (7, 0)), [(5, (14, 0)), [], [], [], []], [(5, (14, 1)), [], [], [], []], [(5, (15, 0)), [], [], [], []], [(5, (15, 1)), [], [], [], []]], [(4, (7, 1)), [(5, (14, 2)), [], [], [], []], [(5, (14, 3)), [], [], [], []], [(5, (15, 2)), [], [], [], []], [(5, (15, 3)), [], [], [], []]]], [(3, (3, 1)), [(4, (6, 2)), [(5, (12, 4)), [], [], [], []], [(5, (12, 5)), [], [], [], []], [(5, (13, 4)), [], [], [], []], [(5, (13, 5)), [], [], [], []]], [(4, (6, 3)), [(5, (12, 6)), [], [], [], []], [(5, (12, 7)), [], [], [], []], [(5, (13, 6)), [], [], [], []], [(5, (13, 7)), [], [], [], []]], [(4, (7, 2)), [(5, (14, 4)), [], [], [], []], [(5, (14, 5)), [], [], [], []], [(5, (15, 4)), [], [], [], []], [(5, (15, 5)), [], [], [], []]], [(4, (7, 3)), [(5, (14, 6)), [], [], [], []], [(5, (14, 7)), [], [], [], []], [(5, (15, 6)), [], [], [], []], [(5, (15, 7)), [], [], [], []]]]], [(2, (1, 1)), [(3, (2, 2)), [(4, (4, 4)), [(5, (8, 8)), [], [], [], []], [(5, (8, 9)), [], [], [], []], [(5, (9, 8)), [], [], [], []], [(5, (9, 9)), [], [], [], []]], [(4, (4, 5)), [(5, (8, 10)), [], [], [], []], [(5, (8, 11)), [], [], [], []], [(5, (9, 10)), [], [], [], []], [(5, (9, 11)), [], [], [], []]], [(4, (5, 4)), [(5, (10, 8)), [], [], [], []], [(5, (10, 9)), [], [], [], []], [(5, (11, 8)), [], [], [], []], [(5, (11, 9)), [], [], [], []]], [(4, (5, 5)), [(5, (10, 10)), [], [], [], []], [(5, (10, 11)), [], [], [], []], [(5, (11, 10)), [], [], [], []], [(5, (11, 11)), [], [], [], []]]], [(3, (2, 3)), [(4, (4, 6)), [(5, (8, 12)), [], [], [], []], [(5, (8, 13)), [], [], [], []], [(5, (9, 12)), [], [], [], []], [(5, (9, 13)), [], [], [], []]], [(4, (4, 7)), [(5, (8, 14)), [], [], [], []], [(5, (8, 15)), [], [], [], []], [(5, (9, 14)), [], [], [], []], [(5, (9, 15)), [], [], [], []]], [(4, (5, 6)), [(5, (10, 12)), [], [], [], []], [(5, (10, 13)), [], [], [], []], [(5, (11, 12)), [], [], [], []], [(5, (11, 13)), [], [], [], []]], [(4, (5, 7)), [(5, (10, 14)), [], [], [], []], [(5, (10, 15)), [], [], [], []], [(5, (11, 14)), [], [], [], []], [(5, (11, 15)), [], [], [], []]]], [(3, (3, 2)), [(4, (6, 4)), [(5, (12, 8)), [], [], [], []], [(5, (12, 9)), [], [], [], []], [(5, (13, 8)), [], [], [], []], [(5, (13, 9)), [], [], [], []]], [(4, (6, 5)), [(5, (12, 10)), [], [], [], []], [(5, (12, 11)), [], [], [], []], [(5, (13, 10)), [], [], [], []], [(5, (13, 11)), [], [], [], []]], [(4, (7, 4)), [(5, (14, 8)), [], [], [], []], [(5, (14, 9)), [], [], [], []], [(5, (15, 8)), [], [], [], []], [(5, (15, 9)), [], [], [], []]], [(4, (7, 5)), [(5, (14, 10)), [], [], [], []], [(5, (14, 11)), [], [], [], []], [(5, (15, 10)), [], [], [], []], [(5, (15, 11)), [], [], [], []]]], [(3, (3, 3)), [(4, (6, 6)), [(5, (12, 12)), [], [], [], []], [(5, (12, 13)), [], [], [], []], [(5, (13, 12)), [], [], [], []], [(5, (13, 13)), [], [], [], []]], [(4, (6, 7)), [(5, (12, 14)), [], [], [], []], [(5, (12, 15)), [], [], [], []], [(5, (13, 14)), [], [], [], []], [(5, (13, 15)), [], [], [], []]], [(4, (7, 6)), [(5, (14, 12)), [], [], [], []], [(5, (14, 13)), [], [], [], []], [(5, (15, 12)), [], [], [], []], [(5, (15, 13)), [], [], [], []]], [(4, (7, 7)), [(5, (14, 14)), [], [], [], []], [(5, (14, 15)), [], [], [], []], [(5, (15, 14)), [], [], [], []], [(5, (15, 15)), [], [], [], []]]]]], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "U_tree = fils_rec(shape, 0, h_max, 0, 0) \n",
    "print U_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul des descendants et des parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcule_desc(U_tree, mem_h_u_todo):\n",
    "    if U_tree == []:\n",
    "        return []\n",
    "    else :\n",
    "        if U_tree[0] in mem_h_u_todo :\n",
    "            rep = [U_tree[0]]\n",
    "        else:\n",
    "            rep = []\n",
    "        if U_tree[1] != [] :\n",
    "            rep += calcule_desc(U_tree[1], mem_h_u_todo)\n",
    "        if U_tree[2] != [] :\n",
    "            rep += calcule_desc(U_tree[2], mem_h_u_todo)\n",
    "        if U_tree[3] != [] :\n",
    "            rep += calcule_desc(U_tree[3], mem_h_u_todo)\n",
    "        if U_tree[4] != [] :\n",
    "            rep += calcule_desc(U_tree[4], mem_h_u_todo)    \n",
    "        return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, (2, 3)), (5, (5, 7))]\n"
     ]
    }
   ],
   "source": [
    "print calcule_desc(U_tree, [(5, (5, 7)), (4, (2, 3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_desc (U_tree, (h, u)):\n",
    "    if U_tree == []:\n",
    "        return None\n",
    "    else :    \n",
    "        if U_tree[0] == (h, u) :\n",
    "            return U_tree\n",
    "        else:\n",
    "            desc_1 = find_desc(U_tree[1], (h, u))\n",
    "            if desc_1 != None:\n",
    "                return desc_1\n",
    "            desc_2 = find_desc(U_tree[2], (h, u))\n",
    "            if desc_2 != None:\n",
    "                return desc_2\n",
    "            desc_3 = find_desc(U_tree[3], (h, u))\n",
    "            if desc_3 != None:\n",
    "                return desc_3\n",
    "            desc_4 = find_desc(U_tree[4], (h, u))\n",
    "            if desc_4 != None:\n",
    "                return desc_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, (2, 3)), [(5, (4, 6)), [], [], [], []], [(5, (4, 7)), [], [], [], []], [(5, (5, 6)), [], [], [], []], [(5, (5, 7)), [], [], [], []]]\n"
     ]
    }
   ],
   "source": [
    "print find_desc(U_tree, (4, (2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcule_asc_path(h,u):\n",
    "    rep = []\n",
    "    for h_inf in range(h, 0, -1):\n",
    "        i_inf = u[0] / (2 ** (h - h_inf))\n",
    "        j_inf = u[1] / (2 ** (h - h_inf))\n",
    "        rep += [(h_inf, (i_inf, j_inf))]\n",
    "    # racine\n",
    "    rep += [(0, (i_inf, j_inf))]\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, (15, 3)), (4, (7, 1)), (3, (3, 0)), (2, (1, 0)), (1, (0, 0)), (0, (0, 0))]\n"
     ]
    }
   ],
   "source": [
    "print calcule_asc_path(5,(15,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_generator(c, h, u):\n",
    "    test_pred = rho[c][h][u] < .5       \n",
    "    if test_pred:\n",
    "        return mu[c][h][u]\n",
    "        #v_predictive = np.random.multivariate_normal(mu[c_predictive][h_path][u_path], Sigma[c_predictive][h_path][u_path], 1)[0]\n",
    "    else:\n",
    "        return np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_generator(c, h, u):\n",
    "    if np.random.random() > rho[c][h][u]:\n",
    "        return np.random.multivariate_normal(mu[c][h][u], Sigma[c][h][u], 1)[0]\n",
    "    else:\n",
    "        return np.zeros(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pi_predictive_sorted(pi_predictive): \n",
    "    pi_predictive_sorted = {}\n",
    "    for c in range(10):\n",
    "        pi_predictive_sorted[c] = []\n",
    "        for k in pi_predictive[c]:\n",
    "            pi_predictive_sorted[c] += [(pi_predictive[c][k], k)]\n",
    "        pi_predictive_sorted[c] = sorted(pi_predictive_sorted[c])\n",
    "    return pi_predictive_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affiche_path_mnist(path_i, path_j):\n",
    "    col_max = max(15, len(path_i))\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, col_max))\n",
    "    b_moins = -.5\n",
    "    b_plus = 31.5\n",
    "    for cpt in range(len(path_i) - 1):\n",
    "        plt.plot(path_j[cpt:cpt + 2],path_i[cpt:cpt + 2], color = colors[col_max - cpt - 1], linewidth= 3)\n",
    "    #plt.plot(path_j,path_i,'r+',markersize=12)\n",
    "    plt.xlim([b_moins,b_plus])\n",
    "    plt.ylim([b_moins,b_plus])\n",
    "    plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood map : `lik_predictive[c][h][u]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual algorithm (see paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_based_policy(sess, test_tensor, log_score, actions_set, mem_h_u):\n",
    "    # actions_set ne contient que les positions de niveau 5\n",
    "    h = h_max - 1\n",
    "    ## 1 ##\n",
    "    z_tilde = np.argmax(log_score)\n",
    "    pi_predictive_plus = {}\n",
    "    ## 2 ## Utilisation de lik_predictive\n",
    "    for u in actions_set:\n",
    "        liste_path = calcule_asc_path(h, u)\n",
    "        log_score_path = np.zeros(10)\n",
    "        test_tensor_copy = copy_test_tensor(test_tensor)\n",
    "        for (h_path, u_path) in liste_path[:-1]:\n",
    "            if (h_path, u_path) not in mem_h_u:\n",
    "                #log_score_path = update_log_score(log_score_path, lik_predictive[z_tilde][h_path][u_path])\n",
    "                v_predictive = argmax_generator(z_tilde, h_path, u_path)\n",
    "                fill_test_tensor(v_predictive, h_path, u_path, test_tensor_copy)\n",
    "                #lik = calc_lik(v,h,u)\n",
    "                #log_score = update_log_score(log_score, lik)\n",
    "        log_score_path = sess.run(y_hat_logit, feed_dict={x_5: test_tensor_copy[5],\\\n",
    "                                                        x_4: test_tensor_copy[4],\\\n",
    "                                                        x_3: test_tensor_copy[3],\\\n",
    "                                                        x_2: test_tensor_copy[2],\\\n",
    "                                                        x_1: test_tensor_copy[1],\\\n",
    "                                                        x_0: test_tensor_copy[0],\\\n",
    "                                                        keep_prob: 1})\n",
    "        pi_path = sess.run(tf.nn.softmax(log_score_path))[0]\n",
    "        print(log_score_path)\n",
    "        pi_predictive_plus[u] = pi_path[z_tilde] \n",
    "    ## 3 ##\n",
    "    keys = pi_predictive_plus.keys()\n",
    "    values = np.array(pi_predictive_plus.values())\n",
    "    k = np.argmax(values)\n",
    "    u_tilde = keys[k]\n",
    "    return u_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scene_exploration(sess, test_tensor, z_ref, ind_test, log_score, actions_set, mem_h_u, record, \\\n",
    "                      POL = 'predictive', AFF = True, THRESHOLD = 1e-4):\n",
    "    \n",
    "    assert POL == 'predictive' or POL == 'saliency-based' or POL == 'random' or POL == 'full'\n",
    "    \n",
    "    if POL == 'full':\n",
    "        THRESHOLD = 0\n",
    "        POL = 'saliency-based'\n",
    "    \n",
    "    TOUR = 0\n",
    "    END = False\n",
    "    h = h_max - 1\n",
    "    \n",
    "    # saliency-based approach\n",
    "    if POL == 'saliency-based':\n",
    "        pi_predictive_sorted = calc_pi_predictive_sorted(pi_predictive_eff)\n",
    "    \n",
    "    while END == False:\n",
    "        \n",
    "        if AFF:\n",
    "            print '************************************'\n",
    "            print '******       TOUR    ' + str(TOUR + 1) + '        ******'\n",
    "            print '************************************'\n",
    "        \n",
    "        # 1. CHOIX\n",
    "        if POL == 'predictive':\n",
    "            u_tilde = prediction_based_policy(sess, test_tensor, log_score, actions_set, mem_h_u)\n",
    "        elif POL == 'saliency-based':\n",
    "            u_tilde = saliency_based_policy(log_score, pi_predictive_sorted, mem_h_u)\n",
    "        else:\n",
    "            u_tilde = random_policy(log_score, mem_h_u)\n",
    "        \n",
    "        if AFF:\n",
    "            print 'CHOIX :', u_tilde\n",
    "        \n",
    "        # 2. LECTURE + UPDATE\n",
    "        liste_path = calcule_asc_path(h, u_tilde)\n",
    "        \n",
    "        for (h_path, u_path) in reversed(liste_path):\n",
    "            if (h_path, u_path) not in mem_h_u:\n",
    "                v = Data_test[z_ref][h_path][u_path][ind_test] \n",
    "                fill_test_tensor(v, h_path, u_path, test_tensor)\n",
    "                \n",
    "                #lik_path = calc_lik(v, h_path, u_path)\n",
    "                #log_score = update_log_score(log_score, lik_path)\n",
    "                log_score = sess.run(y_hat_logit, feed_dict={x_5: test_tensor[5],\\\n",
    "                                                            x_4: test_tensor[4],\\\n",
    "                                                            x_3: test_tensor[3],\\\n",
    "                                                            x_2: test_tensor[2],\\\n",
    "                                                            x_1: test_tensor[1],\\\n",
    "                                                            x_0: test_tensor[0],\\\n",
    "                                                            keep_prob: 1})\n",
    "                pi = sess.run(tf.nn.softmax(log_score))\n",
    "                \n",
    "                mem_h_u += [(h_path, u_path)]\n",
    "                pi = calc_pi(log_score)\n",
    "                H = np.sum(- pi * np.log(pi))\n",
    "                out = np.argmax(pi)\n",
    "                \n",
    "                if AFF :\n",
    "                    print 'pi : ', pi\n",
    "                    print 'out :', out\n",
    "                    print 'pi[out] : ', pi[out]\n",
    "                    print 'H : ', H\n",
    "                \n",
    "                record.mem_pi += [pi]\n",
    "                record.mem_H += [H]\n",
    "                record.mem_z += [out]\n",
    "                record.mem_h_u += [(h_path, u_path)]\n",
    "                record.nb_coeffs += 3\n",
    "                \n",
    "        # 3. INHIBITION OF RETURN        \n",
    "        actions_set.pop(u_tilde)\n",
    "        \n",
    "        record.mem_u += [u_tilde]\n",
    "        record.nb_saccades += 1\n",
    "                \n",
    "        if AFF:\n",
    "            print '****', 'z :', z_ref, ', u :',u_tilde, ' ---> ', out\n",
    "              \n",
    "        #mem_u_final += [u]\n",
    "        #mem_pi_copy += [list(mem_pi)]\n",
    "        #mem_H_copy += [list(mem_H)]\n",
    "        #mem_out += [out]\n",
    "        #if TOUR == 50 or (TOUR >5 and pi[out] > .99999):   \n",
    "        \n",
    "        if TOUR == len(U[h_max - 1]) - 1 or H < THRESHOLD:\n",
    "        #if TOUR == 50 or H < THRESHOLD:\n",
    "            END = True\n",
    "            if AFF :\n",
    "                print '************************************'\n",
    "                print '******         FINI          *******'\n",
    "                print '************************************' \n",
    "            return out\n",
    "            #mem_out_final += [out]\n",
    "            #mem_turn += [TOUR]\n",
    "        else:\n",
    "            TOUR += 1\n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from record import Record            \n",
    "from record import affiche_records   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_TRIALS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/ipykernel/__main__.py:43: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/lib/python2.7/dist-packages/ipykernel/__main__.py:43: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[ -162343.640625   -98519.609375  -321689.25      1030495.5625\n",
      "   -901657.6875     662002.125       35449.71875    616077.1875    2109902.75\n",
      "   3930910.5     ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[ -310841.625    1826122.375    -237461.125   -1334756.375    -498576.09375\n",
      "  -1209442.75     -848929.        273571.8125   1177999.25     2021308.375  ]]\n",
      "[[   51570.61328125   439940.5           58395.25         861167.5625\n",
      "   -267272.78125       19764.03125     -553961.375        922414.75\n",
      "   2525392.5         3142691.        ]]\n",
      "[[ -157149.828125    535187.75       -513349.21875    -403296.21875\n",
      "   -488713.8125      -51459.1015625    66110.6640625    71609.375\n",
      "   2736463.5        2226101.5      ]]\n",
      "[[  100282.5859375   708405.125      -573526.4375      426211.40625\n",
      "  -1002981.1875      245231.1875     -254395.         -214876.765625\n",
      "   2944271.         1936905.75     ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[  360998.53125    -277767.46875     111153.78125     274330.25\n",
      "   -816160.125       229766.125      -126081.4296875   -98373.21875\n",
      "   3527038.75       2681105.25     ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  360998.53125    -277767.46875     111153.78125     274330.25\n",
      "   -816160.125       229766.125      -126081.4296875   -98373.21875\n",
      "   3527038.75       2681105.25     ]]\n",
      "[[  248666.90625   -384507.96875     86745.03125    914840.3125\n",
      "  -1015263.875      417707.84375   -260786.890625   595835.5625    2670929.\n",
      "   4044403.5     ]]\n",
      "[[  622908.75      -256810.546875    -6046.34375   1154816.375    -1229787.5\n",
      "    -94083.609375    23248.03125    102246.734375  2793675.25      2341328.75    ]]\n",
      "[[  360998.53125    -277767.46875     111153.78125     274330.25\n",
      "   -816160.125       229766.125      -126081.4296875   -98373.21875\n",
      "   3527038.75       2681105.25     ]]\n",
      "[[  248666.90625   -384507.96875     86745.03125    914840.3125\n",
      "  -1015263.875      417707.84375   -260786.890625   595835.5625    2670929.\n",
      "   4044403.5     ]]\n",
      "[[ -983098.4375       521399.1875       128855.515625     -47415.7265625\n",
      "    -11844.99609375  -863646.5625      -258766.96875      674885.6875\n",
      "   1893718.25        1713770.375     ]]\n",
      "[[ -447448.65625   -311676.78125   -300234.90625   1067353.75     -1010807.75\n",
      "    956955.         -62840.140625   575180.875     1882806.375     3973811.25    ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[ -552166.25    1419460.625   -418120.375  -1238926.125   -490422.5\n",
      "   -854129.9375  -735963.125    140429.6875  1779082.625   2248760.5   ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  673458.         1015625.125       105900.4453125  -409624.53125\n",
      "     25411.421875    462297.96875    -436620.375       232460.875\n",
      "   2240967.25       2225158.       ]]\n",
      "[[ 1060531.5         784639.0625      165865.8125     -393221.03125\n",
      "    108176.1796875   281932.0625     -339134.59375     -93148.7265625\n",
      "   2148881.75       2356076.       ]]\n",
      "[[ -618720.625     1018133.1875     289747.875     -157642.03125\n",
      "   -177241.390625  -865949.125     -333296.53125    909567.6875    2272105.75\n",
      "   1769012.625   ]]\n",
      "[[ -676033.875        777872.            21154.87890625   149392.5\n",
      "     49587.37890625  -594250.0625      -241425.5          814542.125\n",
      "   2010992.75        1941103.375     ]]\n",
      "[[  591506.3125      1142223.           201808.90625     -428452.53125\n",
      "   -112105.3671875    290523.0625      -448667.15625        7375.50878906\n",
      "   2457144.75        2270866.25      ]]\n",
      "[[ -520843.875     222436.15625   265953.875    1701858.375    -606061.125\n",
      "   1006738.625    -199034.625     702068.       2128365.5      2928033.75   ]]\n",
      "[[  384791.6875    684708.       -824617.875     464299.5     -1095181.125\n",
      "    495435.9375   -136237.03125  -285643.875    2316980.25     1660070.25   ]]\n",
      "[[  275390.8125     172733.875     -330103.25      -261237.515625\n",
      "  -1432997.25       234403.078125  -357489.6875     164144.15625   2890661.\n",
      "   2271562.5     ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[ 1096072.25     716261.875   -749535.5     1018136.9375  -932978.5\n",
      "    882214.6875  -826025.25     332024.8125  1042296.1875  1547352.25  ]]\n",
      "[[  360998.53125    -277767.46875     111153.78125     274330.25\n",
      "   -816160.125       229766.125      -126081.4296875   -98373.21875\n",
      "   3527038.75       2681105.25     ]]\n",
      "[[ -157149.828125    535187.75       -513349.21875    -403296.21875\n",
      "   -488713.8125      -51459.1015625    66110.6640625    71609.375\n",
      "   2736463.5        2226101.5      ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[   70730.9765625  -316538.875       301509.96875    1414778.25      -1039979.\n",
      "    577093.75        -75606.0234375   888640.6875     2454863.75\n",
      "   3594568.75     ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[  258644.953125   -196713.171875    235355.390625    393836.09375\n",
      "   -754408.75        277979.96875    -124003.0703125   -60224.1171875\n",
      "   3444516.5        2543384.5      ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  -25984.61523438  -272963.8125       308326.8125      1510840.125\n",
      "   -778824.875        713598.1875       -47666.03125      784401.625\n",
      "   2547716.          3406108.        ]]\n",
      "[[  962839.8125       759884.375         42355.80859375  -358859.125\n",
      "    169124.359375     451755.375       -229243.40625     -156292.59375\n",
      "   2222128.75        2531727.25      ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  734527.8125     341922.        -187490.90625   -378824.78125\n",
      "   -367123.65625    442364.5       -480764.6875     115348.328125\n",
      "   2474045.75      2483393.75    ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[  275390.8125     172733.875     -330103.25      -261237.515625\n",
      "  -1432997.25       234403.078125  -357489.6875     164144.15625   2890661.\n",
      "   2271562.5     ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  275390.8125     172733.875     -330103.25      -261237.515625\n",
      "  -1432997.25       234403.078125  -357489.6875     164144.15625   2890661.\n",
      "   2271562.5     ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[  202627.875     -554260.         261810.40625    890373.8125\n",
      "  -1039809.3125     382373.84375   -177667.421875   517873.78125   2944959.\n",
      "   4318336.5     ]]\n",
      "[[  202627.875     -554260.         261810.40625    890373.8125\n",
      "  -1039809.3125     382373.84375   -177667.421875   517873.78125   2944959.\n",
      "   4318336.5     ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[   51570.61328125   439940.5           58395.25         861167.5625\n",
      "   -267272.78125       19764.03125     -553961.375        922414.75\n",
      "   2525392.5         3142691.        ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[  4.15069375e+04  -2.26688469e+05  -2.34975672e+05   8.71123500e+05\n",
      "   -1.10182400e+06   4.19916781e+05  -6.60828125e+02   6.40407500e+05\n",
      "    2.26288750e+06   3.91727900e+06]]\n",
      "[[ -681134.0625   1940751.       -439565.6875  -1701552.25     -375046.28125\n",
      "  -1153010.875    -803851.        121053.5625   1426222.875    2099244.5    ]]\n",
      "[[   51570.61328125   439940.5           58395.25         861167.5625\n",
      "   -267272.78125       19764.03125     -553961.375        922414.75\n",
      "   2525392.5         3142691.        ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[   51570.61328125   439940.5           58395.25         861167.5625\n",
      "   -267272.78125       19764.03125     -553961.375        922414.75\n",
      "   2525392.5         3142691.        ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[ -299322.46875   -175013.625      -79382.78125   1087838.75      -640724.5\n",
      "    877648.25       212448.140625   513934.78125   2235199.75      3766133.75    ]]\n",
      "[[  275390.8125     172733.875     -330103.25      -261237.515625\n",
      "  -1432997.25       234403.078125  -357489.6875     164144.15625   2890661.\n",
      "   2271562.5     ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  582356.6875   683445.1875  -422095.0625   350002.5    -1284450.5\n",
      "    472360.75    -540166.375    376843.5625  1734345.75    1956426.875 ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[  202627.875     -554260.         261810.40625    890373.8125\n",
      "  -1039809.3125     382373.84375   -177667.421875   517873.78125   2944959.\n",
      "   4318336.5     ]]\n",
      "[[  4.15069375e+04  -2.26688469e+05  -2.34975672e+05   8.71123500e+05\n",
      "   -1.10182400e+06   4.19916781e+05  -6.60828125e+02   6.40407500e+05\n",
      "    2.26288750e+06   3.91727900e+06]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[  202627.875     -554260.         261810.40625    890373.8125\n",
      "  -1039809.3125     382373.84375   -177667.421875   517873.78125   2944959.\n",
      "   4318336.5     ]]\n",
      "[[ -600983.5625      1687114.75        -565432.625      -1685564.875\n",
      "   -176882.359375   -1243967.75        -771314.6875        19077.26367188\n",
      "   1442607.          2337651.5       ]]\n",
      "[[   51570.61328125   439940.5           58395.25         861167.5625\n",
      "   -267272.78125       19764.03125     -553961.375        922414.75\n",
      "   2525392.5         3142691.        ]]\n",
      "[[  202627.875     -554260.         261810.40625    890373.8125\n",
      "  -1039809.3125     382373.84375   -177667.421875   517873.78125   2944959.\n",
      "   4318336.5     ]]\n",
      "[[ -983098.4375       521399.1875       128855.515625     -47415.7265625\n",
      "    -11844.99609375  -863646.5625      -258766.96875      674885.6875\n",
      "   1893718.25        1713770.375     ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[   51570.61328125   439940.5           58395.25         861167.5625\n",
      "   -267272.78125       19764.03125     -553961.375        922414.75\n",
      "   2525392.5         3142691.        ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[ -310841.625    1826122.375    -237461.125   -1334756.375    -498576.09375\n",
      "  -1209442.75     -848929.        273571.8125   1177999.25     2021308.375  ]]\n",
      "[[   51570.61328125   439940.5           58395.25         861167.5625\n",
      "   -267272.78125       19764.03125     -553961.375        922414.75\n",
      "   2525392.5         3142691.        ]]\n",
      "[[ -157149.828125    535187.75       -513349.21875    -403296.21875\n",
      "   -488713.8125      -51459.1015625    66110.6640625    71609.375\n",
      "   2736463.5        2226101.5      ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  360998.53125    -277767.46875     111153.78125     274330.25\n",
      "   -816160.125       229766.125      -126081.4296875   -98373.21875\n",
      "   3527038.75       2681105.25     ]]\n",
      "[[  248666.90625   -384507.96875     86745.03125    914840.3125\n",
      "  -1015263.875      417707.84375   -260786.890625   595835.5625    2670929.\n",
      "   4044403.5     ]]\n",
      "[[  258644.953125   -196713.171875    235355.390625    393836.09375\n",
      "   -754408.75        277979.96875    -124003.0703125   -60224.1171875\n",
      "   3444516.5        2543384.5      ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[  248666.90625   -384507.96875     86745.03125    914840.3125\n",
      "  -1015263.875      417707.84375   -260786.890625   595835.5625    2670929.\n",
      "   4044403.5     ]]\n",
      "[[ -567652.875       878787.125        43986.6640625    37175.3125\n",
      "     52323.5390625  -513855.59375    -194160.296875    968794.125\n",
      "   2021859.875      1592597.       ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[ -570528.375     1491651.375     -448345.9375   -1302051.875\n",
      "   -456959.71875   -853785.375     -737719.25        73667.859375\n",
      "   1849361.375     2288260.      ]]\n",
      "[[ -573387.1875       802138.125        -20955.21289062   390444.\n",
      "     82570.1484375   -473846.90625     -396072.875        943715.9375\n",
      "   2017038.          1750874.25      ]]\n",
      "[[  926640.8125       940527.125       -313040.375       -639538.1875\n",
      "     74278.984375     468178.65625     -238129.21875        7229.93945312\n",
      "   2337097.75        2663455.5       ]]\n",
      "[[  962839.8125       759884.375         42355.80859375  -358859.125\n",
      "    169124.359375     451755.375       -229243.40625     -156292.59375\n",
      "   2222128.75        2531727.25      ]]\n",
      "[[ -718375.375      872605.9375     179117.640625  -243752.421875\n",
      "   -156070.75      -999690.375     -300239.53125    828655.875     2446671.75\n",
      "   1831769.125   ]]\n",
      "[[ -718375.375      872605.9375     179117.640625  -243752.421875\n",
      "   -156070.75      -999690.375     -300239.53125    828655.875     2446671.75\n",
      "   1831769.125   ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[ -507113.59375    146024.6875     311506.4375    1849890.5       -322226.3125\n",
      "   1377603.         170560.765625   506943.5       2127280.        2654344.      ]]\n",
      "[[  286657.5        781524.0625    -905302.5        401683.875    -1020052.375\n",
      "    470204.9375    -167436.5       -255549.859375  2378652.5       1830857.875   ]]\n",
      "[[ -500646.90625   1460112.75      -371267.875    -1331596.75\n",
      "   -469101.84375   -923769.75      -705098.625      186347.015625\n",
      "   1695827.25      2268021.      ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  275390.8125     172733.875     -330103.25      -261237.515625\n",
      "  -1432997.25       234403.078125  -357489.6875     164144.15625   2890661.\n",
      "   2271562.5     ]]\n",
      "[[ -157149.828125    535187.75       -513349.21875    -403296.21875\n",
      "   -488713.8125      -51459.1015625    66110.6640625    71609.375\n",
      "   2736463.5        2226101.5      ]]\n",
      "[[ 1126652.        824539.125    -490260.90625  1076013.75     -845763.8125\n",
      "   1020043.3125   -679909.625    -244814.34375   742435.8125   1643900.375  ]]\n",
      "[[  360998.53125    -277767.46875     111153.78125     274330.25\n",
      "   -816160.125       229766.125      -126081.4296875   -98373.21875\n",
      "   3527038.75       2681105.25     ]]\n",
      "[[ -157149.828125    535187.75       -513349.21875    -403296.21875\n",
      "   -488713.8125      -51459.1015625    66110.6640625    71609.375\n",
      "   2736463.5        2226101.5      ]]\n",
      "[[  477522.03125     -318647.53125      -18101.375        -18545.96289062\n",
      "   -763582.25         177666.546875     -89633.21875     -130225.96875\n",
      "   3540099.75        2898655.25      ]]\n",
      "[[  248666.90625   -384507.96875     86745.03125    914840.3125\n",
      "  -1015263.875      417707.84375   -260786.890625   595835.5625    2670929.\n",
      "   4044403.5     ]]\n",
      "[[    3757.50805664  -460587.625        220161.59375     1451397.25\n",
      "  -1059974.5          868282.4375       -24658.921875     846515.875\n",
      "   2472452.25        3596725.        ]]\n",
      "[[  360998.53125    -277767.46875     111153.78125     274330.25\n",
      "   -816160.125       229766.125      -126081.4296875   -98373.21875\n",
      "   3527038.75       2681105.25     ]]\n",
      "[[  258644.953125   -196713.171875    235355.390625    393836.09375\n",
      "   -754408.75        277979.96875    -124003.0703125   -60224.1171875\n",
      "   3444516.5        2543384.5      ]]\n",
      "[[  324889.15625   -242237.765625   269518.8125    -118566.890625\n",
      "  -1149841.375     -337761.65625   -154714.96875    435604.96875   2392300.\n",
      "   2761121.75    ]]\n",
      "[[  765652.125     542217.1875    449902.40625  -983579.1875   -935682.125\n",
      "   -706573.0625    716281.         87723.53125  2570425.       2855094.75   ]]\n",
      "[[  -67850.984375  -248563.71875    190855.03125   1315420.875     -886718.625\n",
      "    545588.25       -90733.703125   845702.375     2375701.        3583166.75    ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-d730f65d40b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0mactions_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mz_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscene_exploration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_score\u001b[0m\u001b[0;34m,\u001b[0m                                            \u001b[0mactions_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_h_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m                                             \u001b[0mPOL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAFF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTHRESHOLD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTHRESHOLD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_ref\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mz_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-2bf4113c80b5>\u001b[0m in \u001b[0;36mscene_exploration\u001b[0;34m(sess, test_tensor, z_ref, ind_test, log_score, actions_set, mem_h_u, record, POL, AFF, THRESHOLD)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# 1. CHOIX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPOL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'predictive'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mu_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_based_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_h_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mPOL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'saliency-based'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mu_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaliency_based_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_predictive_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_h_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-465651f69876>\u001b[0m in \u001b[0;36mprediction_based_policy\u001b[0;34m(sess, test_tensor, log_score, actions_set, mem_h_u)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m#log_score = update_log_score(log_score, lik)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlog_score_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat_logit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_tensor_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                                        \u001b[0mx_4\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_tensor_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                                        \u001b[0mx_3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_tensor_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                                        \u001b[0mx_2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_tensor_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                                        \u001b[0mx_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_tensor_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                                        \u001b[0mx_0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_tensor_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                                        \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpi_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_score_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_score_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpi_predictive_plus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_tilde\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "dict_records = {}\n",
    "\n",
    "for POL in ('predictive',):#, 'saliency-based', 'random'):\n",
    "    \n",
    "    dict_records[POL] = {}\n",
    "    \n",
    "    for THRESHOLD in (1e-1,): # 1e-2, 1e-3, 1e-4, 1e-5):\n",
    "        \n",
    "        records = [] \n",
    "        cpt_TRIALS = 0\n",
    "        \n",
    "        for z_ref in range(NB_LABEL):\n",
    "            tic = time.time()\n",
    "            \n",
    "            #NB_TRIALS = len(Data_test[z_ref][0][(0,0)])\n",
    "            \n",
    "            for ind_test in range(NB_TRIALS):\n",
    "                \n",
    "                test_tensor = init_test_tensor(BATCH_SIZE = 1)\n",
    "\n",
    "                # initial\n",
    "                log_score = np.zeros(10)\n",
    "                pi = np.ones(10) / 10\n",
    "                H = np.sum(- pi * np.log(pi))\n",
    "\n",
    "                record = Record()\n",
    "                record.POL = POL\n",
    "                record.THRESHOLD = THRESHOLD\n",
    "                record.z_ref = z_ref\n",
    "                record.mem_pi += [pi]\n",
    "                record.mem_H += [H]\n",
    "\n",
    "                # global coef --> log_score initial\n",
    "                h, u = 0, (0, 0)\n",
    "                mem_h_u = [(h, u)]\n",
    "                v = Data_test[z_ref][h][u][ind_test]\n",
    "                fill_test_tensor(v, h, u, test_tensor)\n",
    "                #lik = calc_lik(v,h,u)\n",
    "                #log_score = update_log_score(log_score, lik)\n",
    "                log_score = sess.run(y_hat_logit, feed_dict={x_5: test_tensor[5],\\\n",
    "                                    x_4: test_tensor[4],\\\n",
    "                                    x_3: test_tensor[3],\\\n",
    "                                    x_2: test_tensor[2],\\\n",
    "                                    x_1: test_tensor[1],\\\n",
    "                                    x_0: test_tensor[0],\\\n",
    "                                    keep_prob: 1})\n",
    "                pi = sess.run(tf.nn.softmax(log_score))\n",
    "                H = np.sum(- pi * np.log(pi))\n",
    "                z_tilde = np.argmax(pi)\n",
    "\n",
    "                record.mem_pi += [pi]\n",
    "                record.mem_H += [H]\n",
    "                record.mem_z += [z_tilde]\n",
    "                record.nb_coeffs += 1\n",
    "\n",
    "                # initial actions set\n",
    "                actions_set = {}\n",
    "                for i in range(16):\n",
    "                    for j in range(16):\n",
    "                        actions_set[(i, j)] = 1\n",
    "\n",
    "                z_final = scene_exploration(sess, test_tensor, z_ref, ind_test, log_score,\\\n",
    "                                            actions_set, mem_h_u, record, \\\n",
    "                                            POL = POL, AFF = False, THRESHOLD = THRESHOLD)\n",
    "                record.z_final = z_final\n",
    "                record.success = z_ref == z_final\n",
    "\n",
    "                records += [record]\n",
    "\n",
    "                #sys.stdout.write('\\rPolicy : %s, threshold : %g, classe %d, step %d, rep : %d' \\\n",
    "                #                     % (POL, THRESHOLD, z_ref, ind_test, z_final)) \n",
    "                #sys.stdout.flush()\n",
    "                \n",
    "            toc = time.time()\n",
    "            print '\\rPolicy : %s, threshold : %g, classe %d, step %d, rep : %d, elapsed time : %g' \\\n",
    "                                % (POL, THRESHOLD, z_ref, ind_test, z_final, toc - tic)   \n",
    "            cpt_TRIALS  += NB_TRIALS\n",
    "\n",
    "        dict_records[POL][THRESHOLD] = records\n",
    "        print '\\n'\n",
    "        print 'Nb trials :', cpt_TRIALS\n",
    "        affiche_records(records)\n",
    "        print '\\n'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[[[ 4.53602969]]]]),\n",
       " 1: array([[[[ 0.,  0.,  0.]]]]),\n",
       " 2: array([[[[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]]]]),\n",
       " 3: array([[[[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]]]]),\n",
       " 4: array([[[[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]]]]),\n",
       " 5: array([[[[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]]]])}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  797189.1875       56386.2421875  -578332.875     -1279845.125\n",
      "   -966177.5         826795.6875      335735.6875     -103963.375\n",
      "   3814599.5        3402091.25     ]]\n"
     ]
    }
   ],
   "source": [
    "test = y_hat_logit.eval(feed_dict={ x_5: test_tensor[5],\\\n",
    "                                    x_4: test_tensor[4],\\\n",
    "                                    x_3: test_tensor[3],\\\n",
    "                                    x_2: test_tensor[2],\\\n",
    "                                    x_1: test_tensor[1],\\\n",
    "                                    x_0: test_tensor[0],\\\n",
    "                                    keep_prob: 1,\\\n",
    "                                    batch_phase:False})\n",
    "\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.nn.softmax(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
