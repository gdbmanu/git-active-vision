{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : generaliser à images 32x32, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from waveimage import WaveImage, calc_dim, calc_U, mnist_reshape_32\n",
    "from waveimage import WaveImage, calc_dim, calc_U, mnist_reshape_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def calc_U(shape, h, h_max): #dim_i, dim_j):\n",
    "    dim_i, dim_j = calc_dim(shape, h, h_max)\n",
    "    U = []\n",
    "    for i in range(dim_i):\n",
    "        for j in range(dim_j):\n",
    "            U += [(i, j)]\n",
    "    return U'''\n",
    "from waveimage import calc_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_reshape_32_buf(x):\n",
    "    assert x.shape == (28 * 28,)\n",
    "    image = x.reshape(28,28)\n",
    "    image = np.append(np.zeros((2,28)), image, axis = 0)\n",
    "    image = np.append(image, np.zeros((2,28)), axis = 0)\n",
    "    image = np.append(np.zeros((32,2)), image, axis = 1)\n",
    "    image = np.append(image, np.zeros((32,2)), axis = 1)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9000"
     ]
    }
   ],
   "source": [
    "B_test = []\n",
    "for i in range(len(mnist.test.images)):\n",
    "    if i % 1000 == 0 :\n",
    "        sys.stdout.write('\\rstep %d' % i) \n",
    "        sys.stdout.flush()\n",
    "    c = mnist.test.labels[i]\n",
    "    image = mnist_reshape_32(mnist.test.images[i])\n",
    "    w = WaveImage(image = image)\n",
    "    data = w.get_data()\n",
    "    for h in range(w.get_h_max()):\n",
    "        data_h = w.get_data()[h]\n",
    "        for u in data_h:\n",
    "            v = data_h[u]\n",
    "            B_test += [(v,(c,h,u))]                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test = [[],[],[],[],[],[],[],[],[],[]]\n",
    "for c in range(10):\n",
    "    Data_test[c] = [{},{},{},{},{},{}] \n",
    "    \n",
    "for d in B_test:\n",
    "    v = d[0]\n",
    "    c = d[1][0]\n",
    "    h = d[1][1]\n",
    "    u = d[1][2]\n",
    "    if u in Data_test[c][h]:\n",
    "        Data_test[c][h][u] += [v]\n",
    "    else:\n",
    "        Data_test[c][h][u] = [v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creation de la base d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_tensor_data(batch_x):\n",
    "    batch_size, _ = batch_x.shape\n",
    "    wave_tensor = {}\n",
    "    for h in range(6):\n",
    "        if h == 0:\n",
    "            h_size = 1\n",
    "            wave_tensor[h] = np.zeros((batch_size, h_size, h_size, 1))\n",
    "        else:\n",
    "            h_size = 2**(h - 1)\n",
    "            wave_tensor[h] = np.zeros((batch_size, h_size, h_size, 3))\n",
    "    for num_batch in range(batch_size):\n",
    "        image = mnist_reshape_32(batch_x[num_batch])\n",
    "        w = WaveImage(image = image)\n",
    "        for h in range(w.get_h_max()):\n",
    "            data_h = w.get_data()[h]\n",
    "            if h == 0:\n",
    "                wave_tensor[h][num_batch][0][0][0] = data_h[(0,0)]\n",
    "            else:\n",
    "                for u in data_h:\n",
    "                    wave_tensor[h][num_batch][u[0]][u[1]][:] = data_h[u]\n",
    "    return wave_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_test_tensor(BATCH_SIZE = 1):\n",
    "    test_tensor = {}\n",
    "    test_tensor[5] = np.zeros((BATCH_SIZE, DIM_5, DIM_5, DEPTH_WAV))\n",
    "    test_tensor[4] = np.zeros((BATCH_SIZE, DIM_4, DIM_4, DEPTH_WAV))\n",
    "    test_tensor[3] = np.zeros((BATCH_SIZE, DIM_3, DIM_3, DEPTH_WAV))\n",
    "    test_tensor[2] = np.zeros((BATCH_SIZE, DIM_2, DIM_2, DEPTH_WAV))\n",
    "    test_tensor[1] = np.zeros((BATCH_SIZE, DIM_1, DIM_1, DEPTH_WAV))\n",
    "    test_tensor[0] = np.zeros((BATCH_SIZE, 1, 1, 1))\n",
    "    return test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_test_tensor(v, h, u, test_tensor, BATCH_SIZE = 1):\n",
    "    test_tensor[h][0][u[0]][u[1]][:] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_test_tensor(test_tensor):\n",
    "    test_tensor_copy = {}\n",
    "    test_tensor_copy[5] = np.copy(test_tensor[5])\n",
    "    test_tensor_copy[4] = np.copy(test_tensor[4])\n",
    "    test_tensor_copy[3] = np.copy(test_tensor[3])\n",
    "    test_tensor_copy[2] = np.copy(test_tensor[2])\n",
    "    test_tensor_copy[1] = np.copy(test_tensor[1])\n",
    "    test_tensor_copy[0] = np.copy(test_tensor[0])\n",
    "    return test_tensor_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Construction du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Obj:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Obj()\n",
    "params.batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = mnist.train.next_batch(params.batch_size)\n",
    "wave_tensor = wave_tensor_data(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction \n",
    "+ 5 couches convolutionnelles : 16 x 16 --> 8 x 8 ; 8 x 8 --> 4 x 4 etc\n",
    "+ 1 couche FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_WAV = 3\n",
    "\n",
    "DIM_5 = 16\n",
    "WIDTH = 2\n",
    "\n",
    "DEPTH_4 = 32\n",
    "DIM_4 = DIM_5 / WIDTH # 8\n",
    "\n",
    "DEPTH_3 = 64\n",
    "DIM_3 = DIM_4 / WIDTH # 4\n",
    "\n",
    "DEPTH_2 = 128\n",
    "DIM_2 = DIM_3 / WIDTH # 2\n",
    "\n",
    "DEPTH_1 = 256\n",
    "DIM_1 = DIM_2 / WIDTH # 1\n",
    "\n",
    "DIM_HIDDEN = 500\n",
    "\n",
    "NB_LABEL = 10\n",
    "\n",
    "STD = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 8192, 32768, 131072, 130000, 5000)\n"
     ]
    }
   ],
   "source": [
    "nb_param_54 = (DEPTH_WAV * WIDTH * WIDTH) * DEPTH_4\n",
    "nb_param_43 = (DEPTH_4 * WIDTH * WIDTH) * DEPTH_3\n",
    "nb_param_32 = (DEPTH_3 * WIDTH * WIDTH) * DEPTH_2\n",
    "nb_param_21 = (DEPTH_2 * WIDTH * WIDTH) * DEPTH_1\n",
    "nb_param_1h = (DEPTH_1 + DEPTH_WAV + 1) * DIM_HIDDEN\n",
    "nb_param_hr = DIM_HIDDEN * NB_LABEL\n",
    "print (nb_param_54, nb_param_43, nb_param_32, nb_param_21, nb_param_1h, nb_param_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEPTH_1 + DEPTH_2 + DEPTH_3 + DEPTH_4 + DEPTH_WAV + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, stddev = 0.1, name = \"dummy\", reuse = False):\n",
    "    #initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    #initial = tf.zeros(shape)\n",
    "    if reuse:\n",
    "        return tf.get_variable(name)\n",
    "    else:\n",
    "        initial = tf.random_normal(shape, stddev = stddev)\n",
    "        return tf.Variable(initial, name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_5 = tf.placeholder(tf.float32, shape=[None, DIM_5, DIM_5, DEPTH_WAV])\n",
    "x_4 = tf.placeholder(tf.float32, shape=[None, DIM_4, DIM_4, DEPTH_WAV])\n",
    "x_3 = tf.placeholder(tf.float32, shape=[None, DIM_3, DIM_3, DEPTH_WAV])\n",
    "x_2 = tf.placeholder(tf.float32, shape=[None, DIM_2, DIM_2, DEPTH_WAV])\n",
    "x_1 = tf.placeholder(tf.float32, shape=[None, DIM_1, DIM_1, DEPTH_WAV])\n",
    "x_0 = tf.placeholder(tf.float32, shape=[None, 1, 1, 1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "batch_phase = tf.placeholder(tf.bool, name='bn_phase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 --> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "W_conv_54_flux1 = weight_variable([WIDTH, WIDTH, DEPTH_WAV, DEPTH_4], \\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_WAV), \\\n",
    "                            name = \"W_conv_54_flux1\")\n",
    "# Graph construction\n",
    "h_conv_4_flux1 = tf.nn.conv2d(x_5, W_conv_54_flux1, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_4_flux1') \n",
    "#h_conv_4_flux1 = tf.nn.conv2d(x_5, W_conv_54_flux1, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_4_flux1') \n",
    "#h_pool_4_flux1 = tf.nn.max_pool(h_conv_4_flux1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_4_flux1')\n",
    "#h_pool_4_bn_flux1 = tf.contrib.layers.batch_norm(h_pool_4_flux1, center=True, scale=True, is_training=batch_phase, scope='h_pool_4_flux1', updates_collections=None)\n",
    "z_conv_4_flux1 = tf.nn.relu(h_conv_4_flux1)\n",
    "\n",
    "#h_conv_4 = tf.nn.conv2d(x_5, W_conv_54, strides=[1, WIDTH, WIDTH, 1], padding='VALID', name='h_conv_4') \n",
    "#h_conv_4_bn = tf.contrib.layers.batch_norm(h_conv_4, center=True, scale=True, is_training=batch_phase, scope='h_conv_4', updates_collections=None)\n",
    "#z_conv_4 = tf.nn.relu(h_conv_4_bn)\n",
    "\n",
    "#cat_conv_4 = tf.concat((z_conv_4, x_4), axis = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 --> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "W_conv_43_flux1 = weight_variable([WIDTH, WIDTH, DEPTH_4, DEPTH_3],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_4), \\\n",
    "                            name = \"W_conv_43_flux1\")\n",
    "\n",
    "h_conv_3_flux1 = tf.nn.conv2d(z_conv_4_flux1, W_conv_43_flux1, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_3_flux1') \n",
    "#h_conv_3_flux1 = tf.nn.conv2d(z_conv_4_flux1, W_conv_43_flux1, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_3_flux1') \n",
    "#h_pool_3_flux1 = tf.nn.max_pool(h_conv_3_flux1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_3_flux1')\n",
    "#h_pool_3_bn_flux1 = tf.contrib.layers.batch_norm(h_pool_3_flux1, center=True, scale=True, is_training=batch_phase, scope='h_pool_3_flux1', updates_collections=None)\n",
    "z_conv_3_flux1 = tf.nn.relu(h_conv_3_flux1)\n",
    "\n",
    "# Graph construction\n",
    "#h_conv_3 = tf.nn.conv2d(cat_conv_4, W_conv_43, strides=[1, WIDTH, WIDTH, 1], padding='VALID', name='h_conv_3') \n",
    "#h_conv_3_bn = tf.contrib.layers.batch_norm(h_conv_3, center=True, scale=True, is_training=batch_phase, scope='h_conv_3', updates_collections=None)\n",
    "#z_conv_3 = tf.nn.relu(h_conv_3_bn)\n",
    "\n",
    "#cat_conv_3 = tf.concat((z_conv_3, x_3), axis = 3)\n",
    "\n",
    "W_conv_43_flux2 = weight_variable([WIDTH, WIDTH, DEPTH_WAV, DEPTH_4],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_WAV), \\\n",
    "                            name = \"W_conv_43_flux2\")\n",
    "\n",
    "h_conv_3_flux2 = tf.nn.conv2d(x_4, W_conv_43_flux2, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_3_flux2') \n",
    "#h_conv_3_flux2 = tf.nn.conv2d(x_4, W_conv_43_flux2, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_3_flux2') \n",
    "#h_pool_3_flux2 = tf.nn.max_pool(h_conv_3_flux2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_3_flux2')\n",
    "#h_pool_3_bn_flux2 = tf.contrib.layers.batch_norm(h_pool_3_flux2, center=True, scale=True, is_training=batch_phase, scope='h_pool_3_flux2', updates_collections=None)\n",
    "z_conv_3_flux2 = tf.nn.relu(h_conv_3_flux2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 --> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "W_conv_32_flux1 = weight_variable([WIDTH, WIDTH, DEPTH_3 , DEPTH_2],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_3 ), \\\n",
    "                            name = \"W_conv_32_flux1\")\n",
    "\n",
    "# Graph construction\n",
    "h_conv_2_flux1 = tf.nn.conv2d(z_conv_3_flux1, W_conv_32_flux1, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_2_flux1') \n",
    "#h_conv_2_flux1 = tf.nn.conv2d(z_conv_3_flux1, W_conv_32_flux1, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_2_flux1') \n",
    "#h_pool_2_flux1 = tf.nn.max_pool(h_conv_2_flux1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_2_flux1')\n",
    "#h_pool_2_bn_flux1 = tf.contrib.layers.batch_norm(h_pool_2_flux1, center=True, scale=True, is_training=batch_phase, scope='h_pool_2_flux1', updates_collections=None)\n",
    "z_conv_2_flux1 = tf.nn.relu(h_conv_2_flux1)\n",
    "\n",
    "#h_conv_2 = tf.nn.conv2d(cat_conv_3, W_conv_32, strides=[1, WIDTH, WIDTH, 1], padding='VALID', name='h_conv_2') \n",
    "#h_conv_2_bn = tf.contrib.layers.batch_norm(h_conv_2, center=True, scale=True, is_training=batch_phase, scope='h_conv_2', updates_collections=None)\n",
    "#z_conv_2 = tf.nn.relu(h_conv_2_bn)\n",
    "\n",
    "#cat_conv_2 = tf.concat((z_conv_2, x_2), axis = 3)\n",
    "\n",
    "W_conv_32_flux2 = weight_variable([WIDTH, WIDTH, DEPTH_4 , DEPTH_3],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_4 ), \\\n",
    "                            name = \"W_conv_32_flux2\")\n",
    "\n",
    "# Graph construction\n",
    "h_conv_2_flux2 = tf.nn.conv2d(z_conv_3_flux2, W_conv_32_flux2, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_2_flux2') \n",
    "#h_conv_2_flux2 = tf.nn.conv2d(z_conv_3_flux2, W_conv_32_flux2, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_2_flux2') \n",
    "#h_pool_2_flux2 = tf.nn.max_pool(h_conv_2_flux2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_2_flux2')\n",
    "#h_pool_2_bn_flux2 = tf.contrib.layers.batch_norm(h_pool_2_flux2, center=True, scale=True, is_training=batch_phase, scope='h_pool_2_flux2', updates_collections=None)\n",
    "z_conv_2_flux2 = tf.nn.relu(h_conv_2_flux2)\n",
    "\n",
    "W_conv_32_flux3 = weight_variable([WIDTH, WIDTH, DEPTH_WAV , DEPTH_4],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_WAV ), \\\n",
    "                            name = \"W_conv_32_flux3\")\n",
    "\n",
    "# Graph construction\n",
    "h_conv_2_flux3 = tf.nn.conv2d(x_3, W_conv_32_flux3, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_2_flux3') \n",
    "#h_conv_2_flux3 = tf.nn.conv2d(x_3, W_conv_32_flux3, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_2_flux3') \n",
    "#h_pool_2_flux3 = tf.nn.max_pool(h_conv_2_flux3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_2_flux3')\n",
    "#h_pool_2_bn_flux3 = tf.contrib.layers.batch_norm(h_pool_2_flux3, center=True, scale=True, is_training=batch_phase, scope='h_pool_2_flux3', updates_collections=None)\n",
    "z_conv_2_flux3 = tf.nn.relu(h_conv_2_flux3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 --> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "W_conv_21_flux1 = weight_variable([WIDTH, WIDTH, DEPTH_2, DEPTH_1],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_2), \\\n",
    "                            name = \"W_conv_21_flux1\")\n",
    "\n",
    "h_conv_1_flux1 = tf.nn.conv2d(z_conv_2_flux1, W_conv_21_flux1, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_1_flux1') \n",
    "#h_conv_1_flux1 = tf.nn.conv2d(z_conv_2_flux1, W_conv_21_flux1, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_1_flux1') \n",
    "#h_pool_1_flux1 = tf.nn.max_pool(h_conv_1_flux1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_1_flux1')\n",
    "#h_pool_1_bn_flux1 = tf.contrib.layers.batch_norm(h_pool_1_flux1, center=True, scale=True, is_training=batch_phase, scope='h_pool_1_flux1', updates_collections=None)\n",
    "z_conv_1_flux1 = tf.nn.relu(h_conv_1_flux1)\n",
    "\n",
    "# Graph construction\n",
    "#h_conv_1 = tf.nn.conv2d(cat_conv_2, W_conv_21, strides=[1, WIDTH, WIDTH, 1], padding='VALID', name='h_conv_1') \n",
    "#h_conv_1_bn = tf.contrib.layers.batch_norm(h_conv_1, center=True, scale=True, is_training=batch_phase, scope='h_conv_1', updates_collections=None)\n",
    "#z_conv_1 = tf.nn.relu(h_conv_1_bn)\n",
    "\n",
    "W_conv_21_flux2 = weight_variable([WIDTH, WIDTH, DEPTH_3, DEPTH_2],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_3), \\\n",
    "                            name = \"W_conv_21_flux2\")\n",
    "\n",
    "h_conv_1_flux2 = tf.nn.conv2d(z_conv_2_flux2, W_conv_21_flux2, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_1_flux2') \n",
    "#h_conv_1_flux2 = tf.nn.conv2d(z_conv_2_flux2, W_conv_21_flux2, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_1_flux2') \n",
    "#h_pool_1_flux2 = tf.nn.max_pool(h_conv_1_flux2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_1_flux2')\n",
    "#h_pool_1_bn_flux2 = tf.contrib.layers.batch_norm(h_pool_1_flux2, center=True, scale=True, is_training=batch_phase, scope='h_pool_1_flux2', updates_collections=None)\n",
    "z_conv_1_flux2 = tf.nn.relu(h_conv_1_flux2)\n",
    "\n",
    "##\n",
    "\n",
    "W_conv_21_flux3 = weight_variable([WIDTH, WIDTH, DEPTH_4, DEPTH_3],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_4), \\\n",
    "                            name = \"W_conv_21_flux3\")\n",
    "\n",
    "h_conv_1_flux3 = tf.nn.conv2d(z_conv_2_flux3, W_conv_21_flux3, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_1_flux2') \n",
    "#h_conv_1_flux3 = tf.nn.conv2d(z_conv_2_flux3, W_conv_21_flux3, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_1_flux2') \n",
    "#h_pool_1_flux3 = tf.nn.max_pool(h_conv_1_flux3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_1_flux3')\n",
    "#h_pool_1_bn_flux3 = tf.contrib.layers.batch_norm(h_pool_1_flux3, center=True, scale=True, is_training=batch_phase, scope='h_pool_1_flux3', updates_collections=None)\n",
    "z_conv_1_flux3 = tf.nn.relu(h_conv_1_flux3)\n",
    "\n",
    "##\n",
    "\n",
    "W_conv_21_flux4 = weight_variable([WIDTH, WIDTH, DEPTH_WAV, DEPTH_4],\\\n",
    "                            stddev = STD / (WIDTH * WIDTH * DEPTH_WAV), \\\n",
    "                            name = \"W_conv_21_flux4\")\n",
    "\n",
    "h_conv_1_flux4 = tf.nn.conv2d(x_2, W_conv_21_flux4, strides=[1, 2, 2, 1], padding='VALID', name='h_conv_1_flux4') \n",
    "#h_conv_1_flux4 = tf.nn.conv2d(x_2, W_conv_21_flux4, strides=[1, 1, 1, 1], padding='SAME', name='h_conv_1_flux4') \n",
    "#h_pool_1_flux4 = tf.nn.max_pool(h_conv_1_flux4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='h_pool_1_flux4')\n",
    "#h_pool_1_bn_flux4 = tf.contrib.layers.batch_norm(h_pool_1_flux4, center=True, scale=True, is_training=batch_phase, scope='h_pool_1_flux4', updates_collections=None)\n",
    "z_conv_1_flux4 = tf.nn.relu(h_conv_1_flux4)\n",
    "\n",
    "##\n",
    "\n",
    "cat_conv_1 = tf.concat((z_conv_1_flux1, z_conv_1_flux2, z_conv_1_flux3, z_conv_1_flux4, x_1, x_0), axis = 3)\n",
    "z_flat1 = tf.reshape(cat_conv_1, [-1, DEPTH_1 + DEPTH_2 + DEPTH_3 + DEPTH_4 + DEPTH_WAV + 1])#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    W_hidden_flux1 = weight_variable([DEPTH_1, DIM_HIDDEN / 5], stddev = STD / DEPTH_1 / 5, name = \"W_hidden_flux1\")\n",
    "    h_hidden_flux1 = tf.matmul(tf.reshape(z_conv_1_flux1, [-1, DEPTH_1]), W_hidden_flux1)\n",
    "    z_hidden_flux1 = tf.nn.relu(h_hidden_flux1)\n",
    "\n",
    "    W_hidden_flux2 = weight_variable([DEPTH_2, DIM_HIDDEN / 5], stddev = STD / DEPTH_2 / 5, name = \"W_hidden_flux2\")\n",
    "    h_hidden_flux2 = tf.matmul(tf.reshape(z_conv_1_flux2, [-1, DEPTH_2]), W_hidden_flux2)\n",
    "    z_hidden_flux2 = tf.nn.relu(h_hidden_flux2)\n",
    "\n",
    "    W_hidden_flux3 = weight_variable([DEPTH_3, DIM_HIDDEN / 5], stddev = STD / DEPTH_3 / 5, name = \"W_hidden_flux3\")\n",
    "    h_hidden_flux3 = tf.matmul(tf.reshape(z_conv_1_flux3, [-1, DEPTH_3]), W_hidden_flux3)\n",
    "    z_hidden_flux3 = tf.nn.relu(h_hidden_flux3)\n",
    "\n",
    "    W_hidden_flux4 = weight_variable([DEPTH_4, DIM_HIDDEN / 5], stddev = STD / DEPTH_4 / 5, name = \"W_hidden_flux2\")\n",
    "    h_hidden_flux4 = tf.matmul(tf.reshape(z_conv_1_flux4, [-1, DEPTH_4]), W_hidden_flux4)\n",
    "    z_hidden_flux4 = tf.nn.relu(h_hidden_flux4)\n",
    "\n",
    "    z_conv_1_flux5 = tf.concat((x_1, x_0), axis = 3)\n",
    "    W_hidden_flux5 = weight_variable([DEPTH_WAV + 1, DIM_HIDDEN / 5], stddev = STD / (DEPTH_WAV + 1) / 5, name = \"W_hidden_flux5\")\n",
    "    h_hidden_flux5 = tf.matmul(tf.reshape(z_conv_1_flux5, [-1, DEPTH_WAV + 1]), W_hidden_flux5)\n",
    "    z_hidden_flux5 = tf.nn.relu(h_hidden_flux5)\n",
    "\n",
    "    z_hidden_concat = tf.concat((z_hidden_flux1, z_hidden_flux2, z_hidden_flux3, z_hidden_flux4, z_hidden_flux5), axis = 1)\n",
    "    W_hidden = weight_variable([DIM_HIDDEN, DIM_HIDDEN], stddev = STD / DIM_HIDDEN, name = \"W_hidden\")\n",
    "    h_hidden = tf.matmul(z_hidden_concat, W_hidden)\n",
    "    z_hidden = tf.nn.relu(h_hidden)\n",
    "    z_hidden_drop = tf.nn.dropout(z_hidden, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W_hidden = weight_variable([DEPTH_1 + DEPTH_2 + DEPTH_3 + DEPTH_4 + DEPTH_WAV + 1, DIM_HIDDEN], stddev = STD / (DEPTH_1 + DEPTH_2 + DEPTH_3 + DEPTH_4 + DEPTH_WAV + 1), name = \"W_hidden\")\n",
    "#h_hidden = tf.matmul(z_flat1, W_hidden)\n",
    "#z_hidden = tf.nn.relu(h_hidden)\n",
    "#z_hidden_drop = tf.nn.dropout(z_hidden, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### readout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W_readout = weight_variable([DIM_HIDDEN, NB_LABEL], stddev = STD / DIM_HIDDEN, name = \"W_readout\")\n",
    "#y_hat_logit = tf.matmul(z_hidden, W_readout)\n",
    "W_readout = weight_variable([DEPTH_1 + DEPTH_2 + DEPTH_3 + DEPTH_4 + DEPTH_WAV + 1, NB_LABEL], stddev = STD / (DEPTH_1 + DEPTH_2 + DEPTH_3 + DEPTH_4 + DEPTH_WAV + 1), name = \"W_readout\")\n",
    "y_hat_logit = tf.matmul(z_flat1, W_readout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss graph¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_hat_logit))\n",
    "\n",
    "#l1_regularizer = tf.contrib.layers.l1_regularizer(\n",
    "#   scale=0.005, scope=None\n",
    "#)\n",
    "#weights = tf.trainable_variables() # all vars of your graph\n",
    "#regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, weights)\n",
    "\n",
    "regularized_loss = classif_loss #+ regularization_penalty # this loss needs to be min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train graph¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer(1e-3).minimize(regularized_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_hat_logit, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = Obj()\n",
    "mem.num_epoch = []\n",
    "mem.classif_eval = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.n_epochs = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1020\t classif : 0.86000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-67fd44e42dca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_mem.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mwave_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwave_tensor_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwave_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0mx_4\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwave_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0mx_3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwave_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0mx_2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwave_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0mx_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwave_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0mx_0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwave_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0mbatch_phase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e1641f96f89f>\u001b[0m in \u001b[0;36mwave_tensor_data\u001b[0;34m(batch_x)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_h\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     \u001b[0mwave_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwave_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_name = \"models/mnist-waveimage-CNN-parallel-basic-500\"\n",
    "\n",
    "if not os.path.isfile(file_name + \".ckpt.index\"):\n",
    "    for num_epoch in range (params.n_epochs):\n",
    "        if num_epoch % 10 == 0:\n",
    "            mem.num_epoch += [num_epoch]\n",
    "            x_test, y_test = mnist.test.next_batch(params.batch_size)\n",
    "            wave_tensor = wave_tensor_data(x_test)\n",
    "            classif_eval = accuracy.eval(feed_dict={x_5: wave_tensor[5],\\\n",
    "                                                    x_4: wave_tensor[4],\\\n",
    "                                                    x_3: wave_tensor[3],\\\n",
    "                                                    x_2: wave_tensor[2],\\\n",
    "                                                    x_1: wave_tensor[1],\\\n",
    "                                                    x_0: wave_tensor[0],\\\n",
    "                                                    y: y_test,\\\n",
    "                                                    keep_prob: 1,\\\n",
    "                                                    batch_phase:False})\n",
    "            mem.classif_eval += [classif_eval]\n",
    "            sys.stdout.write('\\rstep %d\\t classif : %.5f' \\\n",
    "                             % (num_epoch, \\\n",
    "                                classif_eval))\n",
    "        if num_epoch % 1000 == 0:\n",
    "            saver.save(sess,          file_name + \".ckpt\")\n",
    "            pickle.dump(mem,     open(file_name + \"_mem.pkl\", \"wb\"))\n",
    "        batch_x, batch_y = mnist.train.next_batch(params.batch_size) \n",
    "        wave_tensor = wave_tensor_data(batch_x)\n",
    "        train.run(feed_dict={x_5: wave_tensor[5],\\\n",
    "                              x_4: wave_tensor[4],\\\n",
    "                              x_3: wave_tensor[3],\\\n",
    "                              x_2: wave_tensor[2],\\\n",
    "                              x_1: wave_tensor[1],\\\n",
    "                              x_0: wave_tensor[0],\\\n",
    "                              y: batch_y,\\\n",
    "                              keep_prob: 1,\\\n",
    "                              batch_phase:True})\n",
    "else:\n",
    "    saver.restore(sess, file_name + \".ckpt.index\")\n",
    "    mem = pickle.load(open(file_name + \"_mem.pkl\", \"rb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f864bbf7e90>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBGlwV0qpEKTBXSmlQpAGd6WUCkH/H0sBmVlabJDHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8650089810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mem.classif_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "test_tensor = {}\n",
    "test_tensor[5] = np.zeros((1, DIM_5, DIM_5, DEPTH_WAV))\n",
    "test_tensor[4] = np.zeros((1, DIM_4, DIM_4, DEPTH_WAV))\n",
    "test_tensor[3] = np.zeros((1, DIM_3, DIM_3, DEPTH_WAV))\n",
    "test_tensor[2] = np.zeros((1, DIM_2, DIM_2, DEPTH_WAV))\n",
    "test_tensor[1] = np.zeros((1, DIM_1, DIM_1, DEPTH_WAV))\n",
    "test_tensor[0] = np.zeros((1, 1, 1, 1))\n",
    "\n",
    "test = y_hat_logit.eval(feed_dict={ x_5: test_tensor[5],\\\n",
    "                                    x_4: test_tensor[4],\\\n",
    "                                    x_3: test_tensor[3],\\\n",
    "                                    x_2: test_tensor[2],\\\n",
    "                                    x_1: test_tensor[1],\\\n",
    "                                    x_0: test_tensor[0],\\\n",
    "                                    keep_prob: 1,\\\n",
    "                                    batch_phase:False})\n",
    "\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = mnist.test.images, mnist.test.labels\n",
    "wave_tensor = wave_tensor_data(x_test)\n",
    "classif_eval = accuracy.eval(feed_dict={x_5: wave_tensor[5],\\\n",
    "                                        x_4: wave_tensor[4],\\\n",
    "                                        x_3: wave_tensor[3],\\\n",
    "                                        x_2: wave_tensor[2],\\\n",
    "                                        x_1: wave_tensor[1],\\\n",
    "                                        x_0: wave_tensor[0],\\\n",
    "                                        y: y_test,\\\n",
    "                                        keep_prob: 1,\\\n",
    "                                        batch_phase:False})\n",
    "sys.stdout.write('\\rstep %d\\t classif : %.5f' \\\n",
    "                 % (num_epoch, \\\n",
    "                    classif_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d2d809e24c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mu_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mh_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_test_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Data_test' is not defined"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "ind_test = 2\n",
    "u_test = (7, 7)\n",
    "h_test = 5\n",
    "v = Data_test[c][h_test][u_test][ind_test]\n",
    "\n",
    "test_tensor = init_test_tensor()\n",
    "y_test = np.zeros((1, 10))\n",
    "y_test[0, c] = 1\n",
    "\n",
    "fill_test_tensor(v, h_test, u_test, test_tensor)\n",
    "test = y_hat_logit.eval(feed_dict={x_5: test_tensor[5],\\\n",
    "                                        x_4: test_tensor[4],\\\n",
    "                                        x_3: test_tensor[3],\\\n",
    "                                        x_2: test_tensor[2],\\\n",
    "                                        x_1: test_tensor[1],\\\n",
    "                                        x_0: test_tensor[0],\\\n",
    "                                        keep_prob: 1})\n",
    "print test\n",
    "plt.plot(test_tensor[h_test][0][u_test[0]][u_test[1]][:])\n",
    "print v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
